---
title: "Chapter 3 - Importing and Exporting Data"
format:
  html:
    highlight: null
    theme: default
    toc: true
    toc-title: Contents
    toc-location: right
    toc-depth: 3
    number-sections: true 
    link-external-newwindow: true
    embed-resources: true
---

![](../Images/AF_DSC_banner.png){fig-alt="Data Science Campus and Analysis Function logos."}

# Learning Objectives

* Understand the importance of argument order in functions.
* Have an understanding of what packages are.
* Be able to load and install a package.
* Be able to check package versions and R version.
* Be able to import data from multiple formats.
* Be able to inspect loaded data.
* Be able to export data.
* Be able to explore data.


# Functions

So far we have seen many functions, such as:

* sqrt()
* round()
* c()
* list()

You should make it a habit to explore the help files when you are using a function for the first time so you know:

* What required arguments there are.
* What optional arguments there are.
* What default arguments there are (some arguments have a value by default so we can exclude them without error). 

Recall that they follow the form:

>functionName(argument1 = value1, argument2 = value2, and so on)


## How functions work

The seq() function from chapter 2 is the perfect example to reinforce how functions work, as well as common pitfalls.

Let's take a closer look at the help file for seq().

```{r, eval = FALSE}
# Help doc for seq()

?seq

# or

help(seq)

```


![](../Images/seq_helpfile.PNG){fig-alt="Seq() function help file.", width=650px}


### Function help files

Every help file will have a series of sections describing what the function does. It is worth focusing on the description, the usage and especially the arguments first. 

**Description**

For example, in the help file for seq() under **Description**, it tells us it is a function to "Generate regular sequences". 

**Usage**

We can see that seq() takes the required arguments:

* from (which is 1 by default)
* to (which is 1 by default)
* by (which is calculated by default)

and the optional arguments:

* length.out 
* along.with


**Arguments**

Here, we can find out what these arguments are:

  - from, to: the starting and maximal end values of the sequence.
  - by number: increment of the sequence.


### How are function arguments resolved?

We used this function when creating vectors, here's a reminder.

```{r}
# Creating a sequence of numbers

seq(from = 2, to = 6, by = 2)

```

Let's consider what happens instead when we **don't** specify the arguments, just their values:

```{r}
# Creating a sequence of numbers - not specifying arguments

seq(1,10)

```

This has generated a sequence of numbers from 1 to 10. In this case we did not supply a value for by, so it took the default value, which in this case is 1.

What if we flip 10 and 1 in this case

```{r}
# Creating a sequence of numbers

seq(10,1)

```

So it is clear that where we place the value is important, because arguments are resolved **by position**, in the order specified in the help documnentation.

So above:

* In the first example, it is assumed that we want a sequence from = 1 that goes to = 10. 
* Then if we swap the numbers it is assumed we want to sequence from = 10 that goes to = 1. 

However, if we name the arguments **explicitly** using argument = value, the order we specify them does not matter. 

Let's see this in action:

```{r}
# Reversing arguments but using argument name

seq(to = 10, from = 1)

```

You can sometimes run into errors with more complicated functions by taking the arguments for granted. Often there are many optional arguments that are resolved (position wise) before the required ones.

>**We would encourage you to specify the arguments and parameters as it makes your code easier to understand**


# Packages

Our default R installation,often referred to as **base R** gives us a lot of functionality out of the box.

A lot of this code has been around since R's first implementation in the 90s. 

If we want to implore the newest methodologies, adopted by the wider R community, then we need to install packages to achieve this.

>**Packages are a collection of functions, compiled code and sometimes data sets which are stored in a library of code within R.**

In order to use a package, we first need to install it:

* R installs packages from [CRAN](https://cran.r-project.org/) **The Comprehensive R Archive Network.** that contains over 20,000 packages.

* You can install packages from outside of CRAN (such as from [GitHub](https://github.com/)) with specific functions. Please be aware of the source and quality in these cases.

Your department may have a slightly different way of installing packages, so clearing this up is a good first port of call.



## Installing Packages

To install a package, we use the code below for **each** new package. 

>**install.packages("package_name")**

>**Important**: You will only need to install packages once, you should either do this in the console, or comment out the line in your script where this is done. 

When installing packages you can either get:

* A Message - Provides information, such as version.

* A Warning - Discusses **masking**, which we will encounter later.

* An error - This means something went wrong and the package did not install. 


### Exercise
::: {.panel-tabset}

### **Exercise**{-}

1. Install the packages below using the **R console** one at a time.

* tidyverse

* janitor

Note that tidyverse is a collection of R packages that follow the same programming paradigm, so will take quite some time to install. 

### **Show Answer**{-}

```{r, eval = F}
# Installing packages

install.packages("tidyverse")

install.packages("janitor")

```

:::

Successful installation should finish with messages as below, sometimes interspersed with some warnings. 

```
## package 'janitor' successfully unpacked and MD5 sums checked
## 
## The downloaded binary packages are in
##  C:\Users\bandai1\AppData\Local\Temp\Rtmpm0ZY69\downloaded_packages
```

## Loading Packages

Think of packages as owning a book; you purchase (install) the book once, and after that when you need to reference it you can pick it off your bookshelf. 

In R we call this loading, and you should always load packages at the very top of your script.

To load a package, use the code:

>**library(package_name)** where the package name is not a string this time. 


### Exercise
::: {.panel-tabset}

### **Exercise**{-}

Load the packages you installed in the prior exercise:

* tidyverse

* janitor

### **Show Answer**{-}

```{r}
# loading packages

library(tidyverse)

library(janitor)

```

:::

There is almost always some output we get when loading packages. Some options are:

* **package "X" was built under R Version "Y"** - this states that your R version may be lower than the one the package was written using. This is not always an issue, but you should endeavour to remain updated with your software. 

* **The following objects are masked from "package::package_name":** - this arises when functions from your newly loaded package have identical names to either a function in base R, or from another outside package.
    * As such, the package you loaded takes precedence, and it's function under that name will be used. 
    * You can get around this by using the syntax **package_name::function_name** as R will attempt to autofill the functions from that package, and there is no way to misconstrue what package the function comes from. 


## R and Package Versions
::: {.panel-tabset}

Returning to the versions issue, we may have an older version of R than the one the package was built for.

### **Check R Version** {-}

We can check R version by running this command.

```{r}
# To check the version of R

version
```

You can see that we are running 4.1.3

If your version is a little older, this is fine, but we **thoroughly** recommend versions 4.1 and above and discourage versions beginning with a 3.

Older versions, such as 3.6.3 (which is popular) are no longer supported by the creators, and will conflict with almost all training you will engage with whilst learning. 


### **Check Package Version**{-}

Use the packageVersion() function with the package supplied as a string.

```{r}
# Checking the package version

packageVersion("tidyverse")
```

You see that we have the up to date 2.0.0, this is backwards compatible with some older versions, but beware of argument name changes to functions.

If you are working collaboratively you should always check that you are all using the same versions of packages. 


### **Masked Objects**{-}

One of the masks at play with tidyverse is the **filter()** functions:

* Base R has a filter() function to apply on time series
* Whereas dplyr (a tidyverse package for data manipulation) has a filter() function to select rows or columns from datasets.

These both take very different parameters, so it is important to know what we have masked. After loading the tidyverse, it will assume we want to use the dplyr version of filter going forward. 

To use the alternative we would need to type 

>**stats::filter()**

:::


# Tidyverse

Here we will introduce the tidyverse, a collection of R packages that that changed the way many work with R forever. 

The packages in tidyverse share a common philosophy for data manipulation and exploration so they work well together. 

This philosophy is that of Tidy Data, described first in the [seminal paper](https://vita.had.co.nz/papers/tidy-data.pdf) by Hadley Wickham, the tidyverse's creator. 

## Advantages of the Tidyverse

The tidyverse is

* Well documented. Each sub-library has its own website containing a 'cheat-sheet' and vignettes. We thoroughly recommend bookmarking these.
    * The packages panel has links to the documentation of the package version you have

* Well established in the R data science community, meaning common issues and queries are already answered on platforms such as [Stack Overflow](https://stackoverflow.com/questions/tagged/r).

* Designed such that all sub packages follow a core 'philosophy' which encourages best practices. 

* Open-source software and free to use. As are the books written by the tidyverse creator Hadley Wickham. The highest recommendation we can make is [R for Data Science](https://r4ds.hadley.nz/). 


## Disadvantages

* Like R, tidyverse can have a steep learning curve, and its reliance on functional programming can confuse beginners. 
    * It is argued that this is well worth the investment though.

* It is incredibly flexible, which makes it hard to determine which solutions to problems are the best.

* Quite verbose (wordy), which can lead to long scripts. 


## tidyverse Breakdown{-}

Below is a list of the core packages in tidyverse to provide some awareness into what they make possible:

* [readr](http://readr.tidyverse.org) - Data Import
* [tibble](https://tibble.tidyverse.org/) - Tibbles, a modern re-imagining of data frames
* [tidyr](https://tidyr.tidyverse.org/) - Data Tidying
* [dplyr](https://dplyr.tidyverse.org/) - General Data Manipulation
* [stringr](https://stringr.tidyverse.org/) - Strings Manipulation
* [forcats](https://forcats.tidyverse.org/) - Factors Manipulation
* [ggplot2](https://ggplot2.tidyverse.org/) - Data Visualisation
* [purrr](https://purrr.tidyverse.org/) - Functional Programming
* [lubridate](https://lubridate.tidyverse.org/) - For dealing with dates and times - included in tidyverse 2.0.0 onwards. 


![\Image showing visual representation of tidyverse packages and workflow](../Images/tidyverse.png){fig-alt="Tidyverse workflow of import, tidy, transform/model/visualise and communicate."}

The first of the core packages we will delve into is **readr** which deals with reading in data. We need an understanding of the working directory beforehand.


# Working Directory

R has a powerful notion of the working directory. This is where R looks for files that you ask it to load, and where it will put any files that you ask it to save. 

We often refer to this as the "starting point" when R looks for a file you specified the path for.

Thankfully, we are using an **R project**, which makes filepaths and directories reproducible, by ensuring everyone who opens the project has this set by default.

>**If you are not using a project (we recommend you do) you will need to set your own working directory with the [setwd() function](https://www.geeksforgeeks.org/how-to-use-setwd-and-getwd-in-r/) that requires a full path to the directory to change it manually.**

## Checking Working Directory

The getwd() function (get working directory) is ideal.

```{r}
# Getting the working directory

getwd()
```

If you are inside the project created within these materials, you should have the same final step in the "path", that of the "Course_content" folder.

> **In Windows file paths are specified using back slashes, but in R a backslash already has a meaning, so we use a forward slash or two back slashes instead.**


Base R has many functions that allow you to explore directories, such as:

* dir() - Lists contents of current directory

which are beyond the scope of what we are currently discussing. 


# Reading in Data

There are a variety of ways of reading data into R, in this chapter we will look at reading data using the packages:

* readr - loaded with tidyverse
* readxl - installed with tidyverse, but loaded separately. 


## Readr

The package provides a fast and friendly way to read data from:

* Comma Separated Value (csv) files
* Tab Separated Value (tsv) files

converting them to **tibbles**, which are the required data structure in the tidyverse. 

This is done by using a family of functions, which is a set of functions that have the same prefix:

> **read_filetype()**

The most common, and one we will use throughout the course is **read_csv()**

> Before importing your data you need to know:

* Where it is stored?

* What kind of file is it?

* Are there missing values in the data?
    * Missing values in R are denoted by **NA**.

The code will take the following form:

>**data_name <- read_csv(file_path)**

and readr will:

* Assume the first row of your data is the headings of the columns.

* Attempt to guess the datatype of columns, given their content. If a numeric column contains 99 doubles and one character, then the same coercion that happened with vectors will happen again (since columns are vectors) and we get a character column.
    * One of the first data checks you should do is that the types of the columns match what you expect. 


### Example - Our first filepaths
::: {.panel-tabset}

Let's load in the titanic dataset in the "Data" folder. 

We need to figure out where this is and how to get there from our current working directory, so that we can tell R. 

### **Absolute Filepaths**{-}

An **absolute** or full filepath is constructed as:

>"starting_drive/step_1/step_2/step_3/..../destination

this details the full path taken to reach the file.

To reach "titanic.csv" the absolute filepath for us is 

>"C:/Users/marshj1/af_introduction_to_r/Data/titanic.csv"

### **Relative Filepaths**{-}

A **relative** filepath is the path to reach the file relative to the current working directory. 

Thus we are already part of the way there, and just need to tell R where to go from here:

>"working_directory/step_1/step_2/.../destination

However, in our case our working directory is one level deeper than it should be, inside the course content folder.

As such, we start our relative path by leaving the current folder, or **jumping back a level**, we denote this with two dots, or **../** as the first step of the path.

So, our relative filepath to the dataset here is:

>"../Data/titanic.csv" - Leave the course content folder, go inside the Data folder, select titanic.csv

### **Loading in the data**{-}

Of course, we need to consider where we create our R Projects going forward, as this directly impacts our filepaths. 

```{r}
# Read in titanic with read_csv()

titanic_data <- read_csv("../Data/titanic.csv")
```

You will get some information on:

* rows and columns
* lists of each column types

### **Inspect Data**{-}

Running the name of the variable generates a large output, it is better to use inspection functions from base R and the tidyverse. 

One example is View(), which opens a separate tab in the code editor pane with the dataset.

We will see better examples soon.

```{r eval=FALSE}
# Viewing the data u

View(titanic_data)
```

:::

### Exercise
::: {panel-tabset}

### **Exercise**{-}

1. Having read in the titanic data above, have a look at the column Age of passenger.

2. What type of data would you expect this column to be?

3. Use the "str()" function to see the data type R has set it to be.


### **Show Answer**{-}

1. Have a look at the column Age of passenger.

2. The column looks numeric.

3. 
```{r}
# Using the str() function

str(titanic_data)
```

We can see that R has classed the column as character because of the **.** and asterisk **(*)** within it.

:::

### Dealing with Missing Values at Read-in

Whilst we cannot observe all missing values at this stage, examples that cause columns to be cast to unexpected data types are often spotted quickly.

We can easily correct this by adding an additional argument to the **read_csv()** function.

```{r}
# Specifying missing values as a vector to read_csv()

titanic_data <- read_csv("../Data/titanic.csv", 
                           na = c("*", ".", "", "NULL"))

```

This is read as:

> **Where there is the a `.`, `*` and a blank space, class is it as a missing value.**

We can now see that the . and * in the age column have been replaced with NA's and the age column is now numeric.

You may see all sorts of missing values in practice, deriving from data entry:

* negative numbers where it makes no sense
* abnormally large values such as 999999

>**There are many other useful arguments you can use when reading in data, check the help documentation for read_csv() for details.**


## Readxl

We use readxl to read excel data into R, it supports both .xls and .xlsx formats.

The code below demonstrates how you can read excel data.

```{r eval=FALSE}
dataframe_name <- readxl::read_excel(file_path)
```  

One handy thing to know is the **excel_sheets()** function.

As excel files often have multiple sheets, this function will provide the names without having to open the file.

We run this function with the code below:

```{r eval=FALSE}
# To find out the excel sheet names from excel file

readxl::excel_sheets(file_path)
```


## Example 

1. Read in the excel file Police data.

```{r}
# Reading in excel data using the readxl package
# assigning the file name police_data
# and read_excel function

police_data <- readxl::read_excel("Data/police_data.xlsx")
```

After reading in the file our data should look like this.

![](../Images/police_data_sheet_1.PNG){fig-alt="Police data with one column describing the content of the dataset."}

This is the first sheet in our excel which is just the "Notes".

If we dont specify which sheet, the default setting from readxl is to give us the first sheet.


2. Use the excel_sheets function to see the names of the sheets in the police data.


```{r}
# finding out the excel sheet names from excel file

readxl::excel_sheets("Data/police_data.xlsx")
```


## Exercise
::: {.panel-tabset}

### **Exercise**{-}

Can you add an additional argument in the read_excel() function to read in the second sheet (Table P1) from the police data.

**HINT - look at the help documentation!**


### Show Answer{-}

You can use the name of the sheet or the number/index. 

```{r, eval=FALSE}

# Using the sheet parameter in 2 ways

police_data <- readxl::read_excel("Data/police_data.xlsx",
                                  sheet = 2)

# Alternatively

police_data <- readxl::read_excel("Data/police_data.xlsx",
                                  sheet = "Table P1")

```

Our file should now look like this,

![](../Images/sheet_2.PNG){fig-alt="The police dataset with columns using numbers as names."}

As we can see the top columns are mostly blank with no real significant data, to get around this we can add in a range of columns and rows that have the data we want to analyse. This sorts out the column names as well.


```{r}
# Using the range parameter as well as sheet


police_data <- readxl::read_excel("Data/police_data.xlsx",
                                  sheet = 2, 
                                  range = "A5:AA48")

```

:::

# Exporting the Data

When you read a file into R, the data is loaded into memory. This means that any changes you make won't be reflected in the original file you loaded. If you want to preserve the changes you make to the dataset you have to export the data object to a file.

Exporting tables works in much the same way as importing it.

readr allows us to export to csv file type or equivalent using the **`write.csv()`** function.

As an example we will export the police data we just imported.

```{r, eval=FALSE}
# Exporting data using write_csv()

readr::write_csv(police_data, path = "Data/test.csv")
```

Our data frame police_data would now be stored as test.csv in the Data/ folder.


# A Note on File Paths

You may see some file paths that start with two full stops such as "../Data/titanic.csv" - the .. moves up a level in the folder structure.

We may have a file structure that looks like this:

![](../Images/folder_structure.jpg){fig-alt="Top level is introduction to R, folders are at level 2, items in the folders are level 3."}

Our default working directory may not be in the level 1 location - "Introduction to R". In fact if we create RMarkdown documents our working directory is in the folder the .rmd file is located. Here that would be in the Course Content folder.

From this location "Introduction to R /Course Content" I can move between chapters but I can't move to titanic.csv or img_1.jpg.

If I want to access the titanic file in the Data folder I need to ensure my file path is "../Data/titanic.csv". I need to move up a level in my file structure (using ..) before I can move forwards into the Data folder and my file.

This is explained in more detail in the course in the Introduction to Command Line course on the Learning Hub. 


# Inspecting  the Data

After importing our data, the first thing we may want to do is have a quick look at it to check it looks how we expect it to.

We can do this by typing the various commands in the following exercise.


## Exercise
::: {.panel-tabset}

### **Functions**{-}

Have a play around with each command and see if you can figure out what they are doing.

```{r eval=FALSE}
# Inspecting our data

str(titanic)

dplyr::glimpse(titanic)

dplyr::slice_sample(titanic, n = 5)

head(titanic) 

tail(titanic) 

dim(titanic)

nrow(titanic)

ncol(titanic)

names(titanic)

summary(titanic)

titanic[1,1] 

titanic[3:6,] 

# Type the code below and press tab

titanic$

# Note this brings up some columns - you MUST select one before trying the next command or you will get an error
  
unique(titanic$Pclass)


```


### **Show Answer**{-}

```{r eval=FALSE}

library(dplyr)

str(titanic) # Structure of the table

dplyr::glimpse(titanic)  # Similar to str -  but from dplyr package

dplyr::slice_sample(titanic, n = 5) # Selects a random sample of n rows from the dataset

View(titanic)  # Pops file into a Viewer.

head(titanic) # Top of the table

tail(titanic) # Bottom of the table

dim(titanic) # Dimensions

nrow(titanic) # Number of rows

ncol(titanic) # Number of columns

names(titanic) # Names of columns

summary(titanic) # Summary statistics for data

# Selecting elements

titanic[1,1] # Selecting the first row and column

titanic[3:6,] # Selecting row 3 to 6 and all columns

titanic$Fare # Selecting a column from the dataset

unique(titanic$Pclass) # Tells us the unique elements of a variable.


```

:::

# Summary

We have covered a lot material for importing and exporting and yet there is still so much more to cover with the readr package. 

By no means are you expected to remember all the above, what is better is that you understand the problems you want to solve and can then use the references or material provided (or you find yourself) to go about solving it.

In the next chapter we will look at data manipulation with the dplyr package from the tidyverse. 
