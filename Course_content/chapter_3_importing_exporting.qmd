---
title: "Chapter 3 - Importing and Exporting Data"
format:
  html:
    highlight: null
    theme: default
    toc: true
    toc-title: Contents
    toc-location: right
    toc-depth: 3
    number-sections: true 
    link-external-newwindow: true
    embed-resources: true
---

![](../Images/AF_DSC_banner.png){fig-alt="Data Science Campus and Analysis Function logos."}

# Learning Objectives

**The goal of this chapter is to:**

* Understand the importance of argument order in functions.
* Have an understanding of what packages are.
* Be able to load and install a package.
* Be able to check package versions and R version.
* Be able to import data from multiple formats.
* Be able to inspect loaded data.
* Be able to export data.
* Be able to explore data.


# Functions

We have now used a few functions, we will go through a little bit more information about how they work. Please note that there is a course on Functions, Loops and Control flow on the Learning Hub that covers creating user defined functions in more detail.

You should make it a habit to explore the help files when you are using a function for the first time so you know what the default settings are and to see what things you can control with different function arguments.

Functions follow the form:

>functionName(argument1 = value1, argument2 = value2, and so on)

Let's take a look at an example of a function.


## How functions work: the seq() function

Let’s try using seq() which makes regular sequences of numbers.

We used it in creating vectors. 

Let's take a closer look at the help file for seq().

```{r Helpfile for seq(), eval = FALSE}

# Looking at R help documentation
# for the sequence function

?seq

```


![](../Images/seq_helpfile.PNG){fig-alt="Seq() function help file.", width=650px}


## Function help files

Every help file will have a series of sections describing what the function does. I generally focus first on: **Description**, **Usage**, **Arguments**, and **Examples**. 

**Description**

For example, in the help file for seq() under **Description**, it tells us it is a function to "Generate regular sequences". 

**Usage**

We can see that seq() takes the arguments from, to, and by, and the optional arguments length.out and along.with. 

**Arguments**

Here, we can find out what these arguments are:

  - from, to: the starting and maximal end values of the sequence.
  - by number: increment of the sequence.


## How are function arguments resolved?

We used this function when creating vectors, like below.

```{r}

# Creating a sequence of numbers
# Here I am specifying the arguments

seq(from = 2, to = 6, by = 2)

```

What happens if we try:

```{r}
# Creating a sequence of numbers
# Here I am NOT  specifying the arguments
# When arguments are specified they are matched by position
# The order of the values matters

seq(1,10)
```

This has generated a sequence of numbers from 1 to 10. In this case we did not supply a value for by, so it took the default value, which in this case is 1.

```{r How are function arguments resolved part 1}
# Creating a sequence of numbers
# Here I am NOT  specifying the arguments
# When arguments are specified they are matched by position
# The order of the values matters

seq(10,1)

```

And what about:

```{r How are function arguments resolved part 2}
# Creating a sequence of numbers
# Here I am specifying the arguments
# When arguments are specified, order specified doesnt matter
# THIS IS HIGLY RECOMMENDED

seq(to = 10, from = 1)

```

The above demonstrates something about how R resolves function arguments. 

You should always specify arguments in the form name = value . If you do not specify, R will attempt to resolve by position. 

So above, first it is assumed that we want a sequence from = 1 that goes to = 10. Then if we swap the numbers it is assumed we want to sequence from = 10 that goes to = 1. If we name the arguments explicitly using name = value, the order of the arguments doesn't matter. 

>**I would encourage you to specify the arguments and parameters as it makes your code easier to understand**


# Packages

Our default R installation – often referred to as **“base R”** gives us a lot of functionality.


A lot of this code has been around since R’s early days, back to when it was created in 1993. However, if we want to do more complicated, newer or more exciting things with our code we can install packages to achieve these goals.


>**Packages are a collection of functions, compiled code and sometimes data sets which are stored in a “library” of code within R.**

In order to use a package, we first need to download it.  
R installs packages from [CRAN](https://cran.r-project.org/) – **The Comprehensive R Archive Network.**

Your department may have a slightly different way of installing packages.

R has over 15,000 packages on CRAN, so it would be impossible to have them all downloaded on your machine. You can also install packages that are not part of CRAN; but please be aware of the source and quality; like any software these can damage your machine if they are malicious.


## Cran Task Views

If you want to find what packages you can use for what task, you can use [Cran task Views](https://cran.r-project.org/web/views/), this gives a brief overview of the packages you can use.


## ONS Note!

Within ONS we use a mirrored version of CRAN on our software repository called **Artifactory**. 

Behind the scenes our R installation is set to install from *Artifactory* rather than *CRAN*. 

This requires our up to date windows username and password. Without this the package will not install. This is why it is important for ONS staff to make sure their password is up to date in either your settings. Some users with a very old version of R may have a .rprofile - we encourage you to update to the new RStudio bundle.


## Installing Packages

To install a package, we use the code below. 


>**It is important we use this WHOLE line of code every time we install a package.**


```{r, eval = F}
# Installing a package

install.packages(“package_name”, dependencies = TRUE, type = “win.binary”)

```

When installing packages you can either get a,

* Message

* Warning 

* An error

Generally a message will mean there is no problem, a warning is usually fine (generally) and an error is not fine, means that something is wrong.


### Exercise
::: {.panel-tabset}

### **Exercise**{-}

1. Try installing the packages below using the **R console.**


   **Run them line by line – this makes it easy to spot any error messages.**


* “tidyverse”

* “janitor”


### **Show Answer**{-}

```{r, eval = F}
# Installing packages

install.packages("tidyverse", dependencies = TRUE, type = "win.binary")

install.packages("janitor", dependencies = TRUE, type = "win.binary")


```

:::

### {-}

Successful installation should finish with messages as below, the last box, the rest are warnings which you will get sometimes.

**With the default colour theme, installing packages generally displays a lot of ominous red text - this is absolutely fine!**


```
## package 'janitor' successfully unpacked and MD5 sums checked
## 
## The downloaded binary packages are in
##  C:\Users\bandai1\AppData\Local\Temp\Rtmpm0ZY69\downloaded_packages
```

## Loading Packages

Think of packages as owning a book; you purchase (install) the book once, and after that when you need to reference it you can pick it off your bookshelf. 

In R we call this loading, and you should always load packages at the very top of your script.

To load a package, use the code below;


```{r eval=FALSE}
# Loading a package

library(package_name)

```

>**Note here there are no quotes around the package name.**


### Exercise
::: {.panel-tabset}

### **Exercise**{-}


Now try to load the packages below.

* readr

* readxl


### **Show Answer**{-}

```{r}

# loading packages

library(readr)

library(readxl)

```

:::

### {-}

You may see a message that says

package "X" was built under R Version "Y" - this states that your R version may be lower than the one the package was written using. This doesn't usually cause issues.

You may also see a message about masked objects - this is explained later in this document.


Now that we've loaded all of the packages in, there is one point that needs to be made about syntax.

When we start typing in a package name, R Studio will usually pop-up a window displaying the various functions available. The list of functions includes all base R functions along with all the functions from any libraries you have loaded in.


```{r, eval = FALSE}

# Press tab after the colons to access the list available functions

readr::
  
readxl::
```


We could select the function we want to use from the list and move on. 

However, a problem arises when multiple functions from different libraries have identical names. It is not always clear which function you're referencing and implementing. We can avoid this by specifying the library before the function, like above.

R Studio will then only display functions available from that library. This ensures we are implementing the correct function and makes our code easier to understand for ourselves and others!

It is considered best practice to always spell out where an external function is coming from with **::** , particularly when writing production code.


## When to load specific packages

Returning to our book analogy, not all of the books you own are relevant to your project. If you are working on a gardening project, a cookbook isn’t very helpful and you wouldn’t need to use it; it’s exactly the same for your R project.

We’re not using janitor in this session so we are not going to load it yet.


## R and Package Versions
::: {.panel-tabset}

You may have gotten a message that says,

**package ‘readr’ was built under R version 3.4.4** 

This means that we are using an older version of R than the one the package is built for.


### **Check R Version** {-}

We can check our R version by running the command version.

```{r}
# To check the version of R

version
```


I am running version 3.4.4.

Dont worry if you are running an older version.

If you are curious on the [release names](https://livefreeordichotomize.com/2017/09/28/r-release-names/), they are references to Peanuts strips/films.

Most packages are fully backwards compatible, so this is something to be aware of but we do not need to worry about it too much.


### **Check Package Version**{-}

To check the version of a package you can type, the code below;

```{r}
# Checking the package version

packageVersion("dplyr")
```

If you are working collaboratively you should always check that you are all using the same versions of packages. 

This helps with the reproducibility of your results and allows everyone on a team to work with the code.


### **Masked Objects**{-}

Some packages **overwrite or “mask”** functions from other existing packages.

The filter function from stats deals with Linear Filtering on a Time Series

dplyr’s version of filter selects rows based on specific conditions.

As you can imagine these both take very different parameters – so it is important to know what we have masked. This is because after we have loaded the dplyr package it will assume we want to use the dplyr version of filter – **NOT** the one from the stats package.

```{r}
# Loading the package dplyr

library(dplyr)
```

:::


# Tidyverse

So far we have seen a quick introduction to base R with vectors being the building blocks of everything else. 

Now we will take a slight detour away from base R to the tidyverse which is a collection of various R packages.

The packages in tidyverse share a common philosophy for data manipulation and exploration so they work well together. We will see the what the majority of the family of packages in tidyverse have to offer, but not all.


## Advantages{-}

tidyverse is:

* Well documented. Each sub-library has its own website containing a 'cheat-sheet', as well as examples and a vignette which goes into further detail. We can access the useful information through several methods. The packages panel is links to the help panel if you click on the package name. The package summary below is hyper-linked to their respective website. 

* Established in the R data science community, meaning common issues and queries are already answered on platforms such as Stack Overflow.

* Designed such that all sub packages follow a core 'philosophy' which encourages best practices. 

* Open-source software and free to use. As are the books written by the tidyverse creator Hadley Wickham. 


## Disadvantages{-}

* Like R, tidyverse can have a steep learning curve, due to its flexibility. There are several ways to solve the same problem and it's not always clear which is best.


## tidyverse Breakdown{-}

Below is a list of the core packages in tidyverse to provide some awareness into what they make possible:

* [`readr`](http://readr.tidyverse.org) - Data Import,
* [`tibble`](https://tibble.tidyverse.org/) - Tibbles, a modern re-imagining of data frames,
* [`tidyr`](https://tidyr.tidyverse.org/) - Data Tidying,
* [`dplyr`](https://dplyr.tidyverse.org/) - General Data Manipulation,
* [`stringr`](https://stringr.tidyverse.org/) - Strings Manipulation,
* [`forcats`](https://forcats.tidyverse.org/) - Factors Manipulation,
* [`ggplot2`](https://ggplot2.tidyverse.org/) - Data Visualisation,
* [`purrr`](https://purrr.tidyverse.org/) - Functional Programming,


Note: The majority of the 'heavy lifting', with respect to data manipulation and exploration, will be done through the functions available through the tidyverse libraries. On some occasions, we will be using functions from other libraries.


![\Image showing visual representation of tidyverse packages and workflow](../Images/tidyverse.png){fig-alt="Tidyverse workflow of import, tidy, transform/model/visualise and communicate."}


# Working Directory

R has a powerful notion of the working directory. This is where R looks for files that you ask it to load, and where it will put any files that you ask it to save. 

RStudio shows your current working directory at the top of the console.


## Checking Working Directory

You can print this out in R code by running getwd().

```{r}
# Getting the working directory

getwd()
```


> **In Windows file paths are specified using back slashes, but in R a backslash already has a meaning, so we use a forward slash or two back slashes instead.**


## Setting Working Directory

You can use **`setwd()`** function and provide an absolute or relative file path to change the working directory to.

> **For example `"C:/My_RStudio/Workspace/Intro_to_R"`**

While you are working on this course, we recommend you set your working directory as the same folder as the course materials you downloaded from the learning hub. 

```{r, eval=FALSE}
# Setting the working directory

setwd("C:/My_RStudio/Workspace/Intro_to_R")
```

>**Alternatively you could use the keyboard short cut CTLR+SHIFT+H.**

Some great base R functions for exploring your directory are:

```{r, eval = FALSE}
# Exploring the directory using file.choose() function

file.choose()

# Exploring the directory using dir() function

dir()

# Exploring the directory using list.files() function

list.files()


```


# Reading in Data

There are a variety of ways of reading data into R, in this chapter we will look at reading data using the readr and readxl packages.

Here are a few other options for various file types:

* haven - SPSS, Stata and SAS files,
* DBI + dplyr or dbplyr - Databases,
* jsonlite - json files,
* httr - Web APIs,
* rvest - HTML (Web Scraping)


## Readr

The package provides a fast and friendly way to read data from *csv* and *tsv* formats, it converts the data into *tibbles*.

For this section we are going to use the **`read_csv()`** function.

Before importing your data you need to know,

* Where it is stored?

* What kind of file it is?

* Are missing values in the data?
    + Missing values in R are denoted by **NA**.

The code below demonstrates how you can read csv data.

```{r, eval=FALSE}
# Reading in CSV data using readr package and read_csv function

dataframe_name <- readr::read_csv(file_path)
```


**Things To Keep in Mind**

readr will assume that the first row of your data is the headings of the columns.

readr will automatically try and guess the data types in your columns, for example:

if a column has only numerical data, it will be classed as numeric or if it only contains logical values it will be classed as logical. If the values do not match then R keeps them as characters. It is good practise to check your column data types, just in case R chose the wrong type automatically.


## Example 

Load the titanic data using the code below,

You will need to change the file path to where titanic.csv is saved in your files.

You will have noticed that we had some parsing information after reading the file in, displayed at the end of the process (as a warning). This is to let us know the data type  for each column. 

This is not an error and its useful to inspect the chosen datatypes. 

```{r}
# Reading in CSV data using readr package and read_csv function

titanic <- readr::read_csv("Data/titanic.csv")
```


To look at the data in R we use the View command as below.


>**Make sure you spell it with a capital V.**


```{r eval=FALSE}
# Viewing the data using the View() function

View(titanic)
```


## Exercise
::: {panel-tabset}

### **Exercise**{-}

1. Having read in the titanic data above, have a look at the column Age of passenger.

2. What type of data is this column?

3. Use the "str()" function to see the data type R has set it to be.


### **Show Answer**{-}

1. Have a look at the column Age of passenger.

2. The data is numeric data.

3. 
```{r}
# Using the str() function

str(titanic)
```

We can see that R has classed the column as character because of the **.** and asterisk **(*)** within it.

We can easily correct this by adding an additional argument when the reading the data to specify that . and * are a missing value.


The code below, can be read as;

> **Where there is the a `.`, `*` and a blank space, class is it as a missing value.**


```{r}
# Importing CSV data using readr package and read_csv function
# Specifying missing values by adding a vector, na=c() of what should be 
# classed as missing values

titanic <- readr::read_csv("Data/titanic.csv", 
                           na = c("*", ".", "", "NULL"))


```


We can now see that the . and * in the age column have been replaced with NA's and the data has been read is as numerical data.

On this instance our missing values have been classed as . and *, missing values in other datasets can be classed as other symbols or words. e.g.: -, -9.

>**Sometimes there are a few lines of metadata at the top of the file. You can use skip = n to skip the first n lines**

```{r, eval=FALSE}
# Please NOTE this is not code
# This will skip the first 5 rows from the csv

dataset_name <- readr::read_csv("file path", 
                           na = c("*", ".", "", "NULL"), # missing value
                           skip = 5) # skips the first 5 rows
```

>**Alternatively we can also skip empty rows as below**

```{r, eval=FALSE}
# Please NOTE this is not code
# Should blank rows be ignored altogether? i.e. If this option is TRUE then blank rows will not be # represented at all. If it is FALSE then they will be represented by NA values in all the columns.

dataset_name <- readr::read_csv("file path", 
                           na = c("*", ".", "", "NULL"), # missing value
                           skip_empty_rows = TRUE) # skips empty rows
```


## Readxl

We use readxl to read excel data into R, it supports both .xls and .xlsx formats.


The code below demonstrates how you can read excel data.


```{r eval=FALSE}
dataframe_name <- readxl::read_excel(file_path)
```  

One handy thing to know is the **excel_sheets()** function.

As excel files often have multiple sheets, this function will provide the names without having to open the file.

We run this function with the code below:

```{r eval=FALSE}
# To find out the excel sheet names from excel file

readxl::excel_sheets(file_path)
```



## Example 

1. Read in the excel file Police data.

```{r}
# Reading in excel data using the readxl package
# assigning the file name police_data
# and read_excel function

police_data <- readxl::read_excel("Data/police_data.xlsx")
```

After reading in the file our data should look like this.

![](../Images/police_data_sheet_1.PNG){fig-alt="Police data with one column describing the content of the dataset."}

This is the first sheet in our excel which is just the "Notes".

If we dont specify which sheet, the default setting from readxl is to give us the first sheet.


2. Use the excel_sheets function to see the names of the sheets in the police data.


```{r}
# finding out the excel sheet names from excel file

readxl::excel_sheets("Data/police_data.xlsx")
```


## Exercise
::: {.panel-tabset}

### **Exercise**{-}

Can you add an additional argument in the read_excel() function to read in the second sheet (Table P1) from the police data.

**HINT - look at the help documentation!**


### Show Answer{-}

You can use the name of the sheet or the number/index. 

```{r, eval=FALSE}

# Using the sheet parameter in 2 ways

police_data <- readxl::read_excel("Data/police_data.xlsx",
                                  sheet = 2)

# Alternatively

police_data <- readxl::read_excel("Data/police_data.xlsx",
                                  sheet = "Table P1")

```

Our file should now look like this,

![](../Images/sheet_2.PNG){fig-alt="The police dataset with columns using numbers as names."}

As we can see the top columns are mostly blank with no real significant data, to get around this we can add in a range of columns and rows that have the data we want to analyse. This sorts out the column names as well.


```{r}
# Using the range parameter as well as sheet


police_data <- readxl::read_excel("Data/police_data.xlsx",
                                  sheet = 2, 
                                  range = "A5:AA48")

```

:::

# Exporting the Data

When you read a file into R, the data is loaded into memory. This means that any changes you make won't be reflected in the original file you loaded. If you want to preserve the changes you make to the dataset you have to export the data object to a file.

Exporting tables works in much the same way as importing it.

readr allows us to export to csv file type or equivalent using the **`write.csv()`** function.

As an example we will export the police data we just imported.

```{r, eval=FALSE}
# Exporting data using write_csv()

readr::write_csv(police_data, path = "Data/test.csv")
```

Our data frame police_data would now be stored as test.csv in the Data/ folder.


# A Note on File Paths

You may see some file paths that start with two full stops such as "../Data/titanic.csv" - the .. moves up a level in the folder structure.

We may have a file structure that looks like this:

![](../Images/folder_structure.jpg){fig-alt="Top level is introduction to R, folders are at level 2, items in the folders are level 3."}

Our default working directory may not be in the level 1 location - "Introduction to R". In fact if we create RMarkdown documents our working directory is in the folder the .rmd file is located. Here that would be in the Course Content folder.

From this location "Introduction to R /Course Content" I can move between chapters but I can't move to titanic.csv or img_1.jpg.

If I want to access the titanic file in the Data folder I need to ensure my file path is "../Data/titanic.csv". I need to move up a level in my file structure (using ..) before I can move forwards into the Data folder and my file.

This is explained in more detail in the course in the Introduction to Command Line course on the Learning Hub. 


# Inspecting  the Data

After importing our data, the first thing we may want to do is have a quick look at it to check it looks how we expect it to.

We can do this by typing the various commands in the following exercise.


## Exercise
::: {.panel-tabset}

### **Functions**{-}

Have a play around with each command and see if you can figure out what they are doing.

```{r eval=FALSE}
# Inspecting our data

str(titanic)

dplyr::glimpse(titanic)

dplyr::slice_sample(titanic, n = 5)

head(titanic) 

tail(titanic) 

dim(titanic)

nrow(titanic)

ncol(titanic)

names(titanic)

summary(titanic)

titanic[1,1] 

titanic[3:6,] 

# Type the code below and press tab

titanic$

# Note this brings up some columns - you MUST select one before trying the next command or you will get an error
  
unique(titanic$Pclass)


```


### **Show Answer**{-}

```{r eval=FALSE}

library(dplyr)

str(titanic) # Structure of the table

dplyr::glimpse(titanic)  # Similar to str -  but from dplyr package

dplyr::slice_sample(titanic, n = 5) # Selects a random sample of n rows from the dataset

View(titanic)  # Pops file into a Viewer.

head(titanic) # Top of the table

tail(titanic) # Bottom of the table

dim(titanic) # Dimensions

nrow(titanic) # Number of rows

ncol(titanic) # Number of columns

names(titanic) # Names of columns

summary(titanic) # Summary statistics for data

# Selecting elements

titanic[1,1] # Selecting the first row and column

titanic[3:6,] # Selecting row 3 to 6 and all columns

titanic$Fare # Selecting a column from the dataset

unique(titanic$Pclass) # Tells us the unique elements of a variable.


```

:::

# Summary

We have covered a lot material for importing and exporting and yet there is still so much more to cover with the readr package. 

By no means are you expected to remember all the above, what is better is that you understand the problems you want to solve and can then use the references or material provided (or you find yourself) to go about solving it.

In the next chapter we will look at data manipulation with the dplyr package from the tidyverse. 
