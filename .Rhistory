# rented_con <- ???
# carry out the t.test()
# Chunk 49: t-test-prac-solution
# select the relevant vectors from the data
unique(energy_data$tenure)
owner_con <- energy_data %>% filter(tenure == "Owner-occupied") %>% pull(consumption)
rented_con <- energy_data %>% filter(tenure == "Privately rented") %>% pull(consumption)
# carry out the t.test()
t.test(owner_con, rented_con)
# Chunk 50: chisq
# first we must derive a contingency table of one categorical variable against another: adults vs bedrooms
# create in format of contingency table using the table() function
ctgcy <- table(energy_data$bedrooms, energy_data$adults)
class(ctgcy) # so this is different from a normal dataframe
# perform the chisq with no corrections
chisq.test(ctgcy, correct = FALSE)
# tile plot - for interest
# energy_data %>%
#  count(bedrooms, adults) %>%
#  ggplot(mapping = aes(x = bedrooms, y = adults)) +
#  geom_tile(mapping = aes(fill = n))
# Chunk 51: cs-quiz
quiz(
question("Why are we getting a warning from R when we try to run a `chisq()` on our table `ctgcy`?",
correct = "Yes! Take another look at `ctgcy`. Some of the values are less than 5!",
allow_retry = TRUE,
answer("We didn't specify an argument that we needed", message = "Actually, we only need to specify the first data argument, and the rest have defaults!"),
answer("We used the wrong function", message = "Nope, it was the right function..."),
answer("The contingency table has some pretty small values in it", correct = TRUE),
answer("The contingency table has the wrong format", message = "Not quite...")
)
)
# Chunk 52: chisq-fixed
# first we must derive a contingency table of one categorical variable against another: adults vs bedrooms
# create in format of contingency table using the table() function
filtered_energy <- energy_data %>% filter(bedrooms %in% c("4","5","6") )%>% filter(adults %in% c("3","4"))
ctgcy <- table(filtered_energy$bedrooms, filtered_energy$adults)
class(ctgcy) # so this is different from a normal dataframe
# perform the chisq with no corrections
chisq.test(ctgcy, correct = FALSE)
# Chunk 53: saving-tests
# save the t.test we just carried out
saved_test <- t.test(temp_june, temp_sep, var.equal = TRUE)
class(saved_test)
# Chunk 54: str-saving
str(saved_test)
# Chunk 55: saving-getting
# get the p value from our saved model
saved_test$p.value
# Chunk 56: formula
# a formula for variables x and a saved as object c
c <- x ~ a
# class of c?
class(c)
# Chunk 58: contrasts
# turn var into a factor
mon <- as.factor(airquality$Month)
# get the levels of the factor
levels(mon)
# get contrasts
contrasts(mon)
# Chunk 59: lookcontrasts
# Chunk 60: lookcontrasts-solution
# make sure that your variable is a factor!
x <- as.factor(energy_data$property_type)
contrasts(x)
# Chunk 61: ind-one-way-anova
# Get the data the way we want it
tenure_data <- energy_data %>%
filter(tenure != "Unknown") %>% # filter out unknown
select(tenure, consumption) # select only the vars we want
# we should have three groups of tenure left , and we want to see the counts
tenure_data %>% group_by(tenure) %>% count()
# Chunk 62: prepare-tenure
# this is hidden prep for the next exercise
tenure_data <- energy_data %>%
filter(tenure != "Unknown") %>% # filter out unknown
select(tenure, consumption) # select only the vars we want
model <- aov(consumption~tenure, data=tenure_data) # model for later
# Chunk 63: aov_ex
# our data is tenure_data
# what should our model be?
# model <- ???
# use summary to access the model output
# summary(model)
# Chunk 64: aov_ex-solution
# our data is tenure_data
# what should our model be?
model <- aov(consumption~tenure, data=tenure_data)
# use summary to access the model output
summary(model)
# Chunk 65: posthoc
# posthoc test - Tukey's test
# TukeyHSD(model)
# Chunk 66: posthoc-solution
# posthoc test - Tukey's test
TukeyHSD(model)
# Chunk 67: adjust
# which methods can we use?
p.adjust.methods
# apply a bonferroni correct to a specified p for n number of post-hoc comparisons
p.adjust(p = 0.2, method = "bonferroni", n = 4)
# Chunk 68: anova2way
# our data
tenure_country <- energy_data %>%
filter(tenure != "Unknown" & country != "Unknown") %>% # filter out unknown
select(tenure, country, consumption) # select only the vars we want
# the 2 way unrelated ANOVA
# to understand both main effects and the interaction effect
tc_model <- aov(consumption ~ country + tenure + (country:tenure), data = tenure_country)
summary(tc_model)
# Chunk 69: anova-quiz
quiz(
question("If I model a one-way-unrelated ANOVA with the formula consumption~tenure from `energy_data`, what is the resulting F value?",
correct = "Yes, you got it",
allow_retry = TRUE,
answer("3.142", message = "I think you'll find that's pi"),
answer("0.941", correct = TRUE),
answer("0.41", message = "That's our degrees of freedom for tenure!"),
answer("0.42", message = "That's the p-value!")
),
question("What is the correct formula for comparing the main effects and interaction effects of properties which differ on age category and are in different regions on consumption?",
correct = "Yes, we use the formula operators + and : here",
allow_retry = TRUE,
answer("`consumption ~ property_age, region, property_age:region`", message = "Remember, we use + instead of commas"),
answer("`consumption ~ property_age + region + property_age*region`", message = "If we use the *, we include the main effects twice!"),
answer("`property_age + region + property_age*region ~ consumption`", message = "Everything is on the wrong side here, and there's a * when we want a :"),
answer("`consumption ~ property_age + region + property_age:region`", correct = TRUE)
)
)
# Chunk 70
# create a univariate model
aq_model <- lm(airquality$Temp ~ airquality$Wind)
# get a summary of the model
summary(aq_model)
# try changing lm() to glm() to see output differences.
# Chunk 71: prepare-lm
# this is hidden prep for the next exercise
# note that the naming convention needs to be the
# same in the predict function to get it to work-
# i.e. the data argument should always be used
# rather than using $
aq_model <- lm(Temp ~ Wind, data =airquality)
# Chunk 72
# look at what the model object contains
names(aq_model)
# get confidence intervals for the coefficients
confint(aq_model)
# get the first 10 residuals of the model
residuals(aq_model)[1:10]
# access just the residual standard error from summary
summary(aq_model)$sigma
# Chunk 73: lm-quiz
quiz(
question("What is the value produced when `aq_model` is accessed using `summary()` and selected with `$r.squared`?",
correct = "Yes, you got it",
allow_retry = TRUE,
answer("0.21", correct = TRUE),
answer("0.12", message = "Try again!"),
answer("0.02", message = "Try again!"),
answer("0.09", message = "Try again!")
)
)
# Chunk 74: lsplotting
# create the plot
# make sure the vars are on the right axes
plot(airquality$Wind, airquality$Temp)
# add the least squares line from our model
# colour red, 'thickness' of 3
abline(aq_model, col = "red", lwd=3)
# Chunk 75: predictlm
# get some new data
# by adding a new row to our original data
new_wind <- data.frame(Wind = c(45, 67, 89))
# use the predict function on new values
# and also get confidence intervals for these
predict(aq_model, newdata = new_wind, interval = "confidence")
# Chunk 76: checklm
# check here
# Chunk 77: lmex
# create a multivariate model
aq_mult_model <- lm(Temp ~ ., data = airquality)
# get a summary of the model
summary(aq_mult_model)
# Chunk 78: prepare-complex
# this is hidden prep for the next exercise
aq_mult_model <- lm(Temp ~ ., data = airquality)
# Chunk 79
# our previous model
aq_mult_model <- lm(Temp ~ ., data = airquality)
# hist to tell us the distribution of residuals
hist(residuals(aq_mult_model))
# Chunk 80
# produce the plots from the model
# beware that this will take a minute!
# Chunk 81
# produce the plots from the model
plot(aq_mult_model)
# for normality of the 'Wind' var
shapiro.test(airquality$Wind)
# for variance homogeneity
# between the months as a grouping var
bartlett.test(airquality$Temp, airquality$Month)
# Chunk 83
# use the variance inflation factor from the car package
car::vif(aq_mult_model)
# all the variance inflation values are fairly close to one
# Chunk 84: modbuild1
# (1) Create your model with multiple predictors
# Don't forget to save it as an object and to take a look at the object using summary()
# (2) Visualise your model
# Using the plots we've seen in the previous two sections, and the ways of
# accessing model elements, have a go at visualising your the model.
# (3) Predict values from new data
# some new data is stored in the object new_en_data
# notice the new data does not contain a value for consumption
# make sure to use the argument newdata, NOT data!
# head(new_en_data)
head(fake_energy_data,n=15)
help("prop.test")
z-test<-prop.test(x= c(200,300),n= c(323,986), alternative='two.sided')
sqrt(ztest$statistic)
z-test<-prop.test(x= c(200,300),n= c(323,986), alternative='two.sided')
ztest<-prop.test(x= c(200,300),n= c(323,986), alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= c(200,300),n= c(323,986), alternative='two.sided')
ztest
ztest$p.value
library(janitor)
library(tidyverse)
# Read in the data
titanic <- read_csv("C:/My_RStudio/Workspace/Intro_to_R_Refresh/Data/titanic.csv",
na=c(""," ","NULL"))
# Clean column names
titanic <- clean_names(titanic)
titanic %>%
summarise(my_mean = mean(fare, na.rm = TRUE)) %>%
view()
titanic %>%
group_by(age_of_passenger) %>%
count(sort = TRUE) %>%
view()
titanic %>%
summarise(my_median = median(fare, na.rm = TRUE)) %>%
view()
range(titanic$fare, na.rm = TRUE)
quantile(titanic$fare, na.rm = TRUE)
# almas to help
titanic %>%
group_by(pclass) %>%
ggplot()+
geom_boxplot(mapping = aes(x = pclass, y = age_of_passenger))
var(titanic$fare, na.rm = TRUE)
sd(titanic$fare, na.rm = TRUE)
titanic %>%
ggplot()+
geom_histogram(mapping = aes(x= fare))
t <- titanic %>%
filter(pclass == 1 & survived ==1)
t
t2 <- titanic %>%
filter(pclass != 1 & survived ==1)
t2
t3 <- titanic %>%
group_by(sex_of_passenger) %>%
count() %>%
adorn_totals()
t4 <- titanic %>%
filter(pclass == 1)
prop.test(x=c(200,300),n=c(323,986), alternative = "two.sided")
chisq.test(titanic$survived, titanic$sex_of_passenger)
chisq.test(titanic$survived, titanic$age_of_passenger)
chisq.test(titanic$survived, titanic$fare)
# question for almas
# is p value probability value???
cor.test(titanic$age_of_passenger, titanic$fare, method = "pearson")
cor.test(titanic$survived, titanic$age_of_passenger, method = "pearson")
#Regression model
my_first_model <- glm(survived ~ age_of_passenger + pclass + sex_of_passenger + sibsp + parch + fare + embarked + cabin,                     data = titanic, family = binomial(link = 'logit'))
summary(my_first_model)
t <- titanic %>%
filter(pclass == 1 & survived ==1)
t
t
t
count(t)
count(t)
titanic %>%
filter(pclass != 1 & survived ==1)
t2 <- titanic %>%
filter(pclass != 1 & survived ==1)
count(t2)
t4 <- titanic %>%
filter(pclass == 1)
count(t4)
t5 <- titanic %>%
filter(pclass != 1)
count(t5)
prop.test(x=c(200,300),n=c(323,986), alternative = "greater")
prop.test(x=c(200,300),n=c(323,986), alternative = "less")
prop.test(x=c(200,300),n=c(323,986), alternative = "two.sided")
ztest<-prop.test(x= c(200,300),n= c(1309,1309), alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= c(200,300),n= c(1309,1309), alternative='two.sided')
ztest
count(t)
p1 <- (200/323)
p2 <- (300/986)
p <- (500/1309)
ee <- (p1-p2)/sqrt(p(1-p)((1/323)+(1/986)))
p1 <- (200/323)
p2 <- (300/986)
p <- (500/1309)
ee <- (p1-p2)/sqrt(p(1-p)((1/323)+(1/986)))
ee <- (p1-p2)/sqrt(p*(1-p)*((1/323)+(1/986)))
ee
aaa <- titanic %>%
filter(pclass== 1 | pclass != 1) %>%
count(survived== 1) %>%
t()
print(aaa)
aaa <- titanic %>%
filter(pclass== 1 | pclass != 1) %>%
count(survived== 1)
print(aaa)
t <- titanic %>%
filter(pclass == 1 & survived ==1
mean(t)-
mean(t)
mean(t, na.rm = TRUE)
t <- titanic %>%
filter(pclass == 1 & survived ==1)
t
ww <- titanic %>%
filter(pclass==1)
mean(ww$survived==1,na.rm=TRUE)
firstclass <- titanic %>%
filter(pclass==1)
x1 <- mean(firstclass$survived==1,na.rm=TRUE)
secondclass <- titanic %>%
filter(pclass!=1)
var(firstclass$survived==1)
var(firstclass$survived==1,na.rm=TRUE)
varince1 <- var(firstclass$survived==1)
varince2 <- var(secondclass$survived==1)
n1 <- count(firstclass$survived==1)
count(firstclass$survived==1,na.rm=TRUE)
n1 <- count(t)
n1
ztest<-prop.test(x= c(200,300),n= c(500,500), alternative='two.sided')
sqrt(ztest$statistic)
finally <-  (x1-x2)/sqrt((varince1/n1)+(varince2/n2))
firstclass <- titanic %>%
filter(pclass==1)
x1 <- mean(firstclass$survived==1,na.rm=TRUE)
secondclass <- titanic %>%
filter(pclass!=1)
x2 <- mean(secondclass$survived==1,na.rm=TRUE)
varince1 <- var(firstclass$survived==1)
varince2 <- var(secondclass$survived==1)
n1 <- 200
n2 <- 300
finally <-  (x1-x2)/sqrt((varince1/n1)+(varince2/n2))
finally
finally <-  (x1-x2)/sqrt((varince1)+(varince2))
finally
firstclass$survived==1
x1 <- mean(firstclass$survived==1,na.rm=TRUE)
finally <-  (x1-x2)/sqrt((varince1/n1)+(varince2/n2))
finally
firstclass <- titanic %>%
filter(pclass==1)
count(firstclass)
count(firstclass$survived==0)
count(firstclass$survived==1)
firstclass <- titanic %>%
filter(pclass==1 & survived == 1)
count(firstclass)
firstclass <- titanic %>%
filter(pclass==1)
x1 <- mean(firstclass$survived==1,na.rm=TRUE)
secondclass <- titanic %>%
filter(pclass!=1)
x2 <- mean(secondclass$survived==1,na.rm=TRUE)
secondclass <- titanic %>%
filter(pclass!=1) %>%
filter(survived==1)
count(secondclass)
secondclass <- titanic %>%
filter(pclass!=1)
firstclass <- titanic %>%
filter(pclass==1)
x1 <- mean(firstclass$survived==1,na.rm=TRUE)
secondclass <- titanic %>%
filter(pclass!=1)
x2 <- mean(secondclass$survived==1,na.rm=TRUE)
varince1 <- var(firstclass$survived==1)
varince2 <- var(secondclass$survived==1)
n1 <- 200
n2 <- 300
finally <-  (x1-x2)/sqrt((varince1/n1)+(varince2/n2))
finally
titanic %>%
filter(survived==1)
hehe <- titanic %>%
filter(survived==1)
count(hehe)
ztest<-prop.test(x= c(200,300),n= c(500,500), alternative='two.sided')
sqrt(ztest$statistic)
count(firstclass)
ztest<-prop.test(x= c(200,300),n= c(1309,1309), alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= c(200,300),n= c(323,986), alternative='two.sided')
sqrt(ztest$statistic)
firstclass1 <- titanic %>%
filter(survived==1)
x1 <- mean(firstclass1$pclass==1,na.rm=TRUE)
x1
x2 <- mean(firstclass1$pclass != 1,na.rm=TRUE)
varince1 <- var(firstclass1$pclass==1)
varince2 <- var(firstclass1$pclass!=1)
firstclass3 <- titanic %>%
filter(survived==1)
filter(pclass==1)
firstclass3 <- titanic %>%
filter(survived==1) %>%
filter(pclass==1)
count(firstclass3)
n1 <- 200
n2 <- 300
finally <-  (x1-x2)/sqrt((varince1/n1)+(varince2/n2))
finally
x1 <- mean(firstclass1$pclass==1,na.rm=TRUE)
x1
x2
varince1
varince2
varince2 <- var(firstclass1$pclass!=1)
varince2
varince11 <- var(firstclass1$pclass==1)
varince22 <- var(firstclass1$pclass!=1)
varince11
varince22
finally <-  (x2-x1)/sqrt((varince11/n1)+(varince22/n2))
finally
ztest<-prop.test(x= c(200,300),n= c(323,986), alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= c(200,300),n= c(500,500), alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= c(200,300),n= c(1309,1309), alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= c(200,300),n= c(323,986), alternative='two.sided')
sqrt(ztest$statistic)
finally <-  (x1-x2)/sqrt((varince11/n1)+(varince22/n2))
finally
hehe <- titanic %>%
filter(survived==1)
count(hehe)
ztest<-prop.test(x= 323 ,n=1309, alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= 323 ,n=986, alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= 200 ,n=986, alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= 200 ,n=300, alternative='two.sided')
sqrt(ztest$statistic)
z_test <- function(my_sample, my_pop, observation){
mean_of_sample <- mean(my_sample, na.rm = TRUE)
mean_of_population <- mean(my_pop, na.rm = TRUE)
number_of_obeservation <- nrow(observation)
my_z_test <- (mean_of_sample - mean_of_population)/
(sd(my_pop)/sqrt(number_of_obeservation))
return(my_z_test)
}
first_class_passengers <- titanic %>%
filter(pclass == 1)
z_test(my_sample = first_class_passengers$survived,
my_pop = titanic$survived,
observation = titanic$survived)
firstclass <- titanic %>%
filter(pclass==1)
x1 <- mean(firstclass$survived==1,na.rm=TRUE)
secondclass <- titanic %>%
filter(pclass!=1)
x2 <- mean(secondclass$survived==1,na.rm=TRUE)
ztest<-prop.test(x= 200 ,n=300, alternative='two.sided')
sqrt(ztest$statistic)
t <- titanic %>%
filter(pclass == 1 & survived ==1)
t
count(t)
t2 <- titanic %>%
filter(pclass != 1 & survived ==1)
t2
count(t2)
t4 <- titanic %>%
filter(pclass == 1)
count(t4)
ztest<-prop.test(x= 200 ,n=323, alternative='two.sided')
sqrt(ztest$statistic)
ztest<-prop.test(x= 200 ,n=1309, alternative='two.sided')
sqrt(ztest$statistic)
count(titanic)
count(titanic$survived)
count(titanic$survived==1)
getwd()
setwd("D:")
getwd()
setwd("D: /Gitarea/Intro_to_R_Refresh")
setwd("D: /Gitarea/Intro_to_R_Refresh/")
setwd("D:/Gitarea/Intro_to_R_Refresh")
getwd()
