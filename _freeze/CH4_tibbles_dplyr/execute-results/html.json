{
  "hash": "5fd5986894156aee6970504680b26a33",
  "result": {
    "markdown": "---\ntitle: \"Chapter 4 - Tibbles and dplyr\"\nauthor: \"Government Analysis Function and ONS Data Science Campus\"\nengine: knitr\nexecute:\n  echo: true\n  eval: false\n  freeze: auto  # re-render only when source changes\n---\n\n\n> To switch between light and dark modes, use the toggle in the top left\n\n# Learning Objectives\n\n* Understand the importance of clean variable names.\n* Be able to clean column names using the janitor package.\n* Understand the use of the pipe operator.\n* Be able to sort data with dplyr's **arrange** verb.\n* Be able to select data with dplyr's **select** verb.\n* Be able to filter data with dplyr's **filter** verb. \n* Be able to transform data with dplyr's **mutate** verb.\n* Be able to join datasets together.\n\n\n# Packages and Data\n\nRemember, the first steps when starting a new script are:\n\n* Load in the packages required for the work.\n* Read in datasets required and assign them to a variable in memory.\n\n## Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\n1. Load the following packages:\n\n* Tidyverse\n* janitor\n\n2. Read in the **titanic.csv** file and assign it to the name \"titanic_data\". Remember to assign null values properly (as in Chapter 3) using the \"na\" parameter. \n\n* Remember that you are in your R project, which sets the working directory to be inside the **Course_content** folder. \n\n3. Have a glimpse of your dataset. \n\n\n### **Show Answer**{-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n# Read in titanic.csv and set null values to be specific symbols\n\ntitanic_data <- read_csv(\"Data/titanic.csv\", \n                           na = c(\"*\", \".\", \"\", \"NULL\"))\n\n# Have a peak\n\nglimpse(titanic_data)\n```\n:::\n\n\n:::\n\n\nAs a reminder, in the titanic dataset our columns are:\n\n* **Pclass**: Passenger’s class, 1 = 1st (Upper), 2 = 2nd(Middle), 3 = 3rd(Lower)\n* **Survived**: Survived (1) or died (0)\n* **Name**: Passenger’s name\n* **Sex**: Passenger’s sex\n* **Age of Passenger**: Passenger’s age\n* **SibSp**: Number of siblings/spouses aboard (excluding the person)\n* **Parch**: Number of parents/children aboard (excluding the person)\n* **Ticket**: Ticket number\n* **Fare**: Fare\n* **Cabin**: Cabin number\n* **Embarked**: Port of embarkation, C = Cherbourg, Q = Queenstown, S = Southampton\n\n\nWe can see more details on the [Data Dictionary](https://www.kaggle.com/c/titanic/data)\n\n\n# Column Names\n\nIn the previous session we stated that every column in a tibble is a variable and it is good practice to not have spaces within variable names, as spaces makes it harder for us to call on the variables when we need to use them.\n\nWhen you enter data in Excel, you most often don’t think too much about what you call each column. After all, you just label them once and as long as they are documented, this isn't given too much thought.\n\nWhen you are working with variables in R though, you need to type the name of each variable, every time you want to work with it. So, it makes sense to make your column names as simple, but meaningful as possible.\n\n## Retuning columns by name\n\nIn base R, to call a column by name and return its contents as a single vector (remember, each column in a tibble is a vector) we use the dollar sign **$** operator.\n\nYou will notice the list of column names will pop up and you can move through them with arrow keys and select the one you want. \n\n### Example\n\nLet's return the column \"Pclass\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Return Pclass with base R\n\ntitanic_data$Pclass\n```\n:::\n\n\nThis returns the entire vector (usually up to 1000 entries) so it would be useful to use **glimpse()** or other inspection functions for a sense check.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Return Pclass and glimpse\n\nglimpse(titanic_data$Pclass)\n```\n:::\n\n\nThis could already prove frustrating due to needing to remember the capital letters, particularly if the autocomplete is slowing down.\n\nHowever, it can get worse if spaces are included in the column name.\n\n### Example - Returning column with spaces\n\nLet's take the \"name of Passenger\" column and try to return it without the auto-complete.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitanic$name Of Passenger\n```\n:::\n\n\nThis will throw an error as spaces in syntax are not allowed, R cannot process code in this way as a space should usually denote the end of a line of code. \n\nTo get around this we enclose column names with spaces in backticks **\\` \\`** and you will notice that the autocomplete does the same. \n\nThis allows the entire column name to be read as one entity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting a column with spaces in the names\n\nglimpse(titanic_data$`name Of Passenger`)\n```\n:::\n\n\nWhilst this works, it is bad practice to use capitalisation and spaces, as it complicates things for us as well as others we collaborate with.\n\n### A word of warning\n\nWhilst this is completely fine in Base R, there are unexpected consequences of using this technique, particularly when making changes to a column using assignment. \n\n* With the tidyverse, when we use its myriad of functions, we can check manipulations on the data without overwriting the underlying variable unless we **explicitly** ask it to do so with **<-**.\n\n* However, with the **$** method, we can overwrite a column for example and this will **implicitly** and permanently change the underlying variable, which we must be careful of.\n\nShould you make a mistake following this choice, you would have to revert back to the original data and read it back in to start from scratch, as recreating data is a nightmare.\n\n### Accessing column names\n\nWe can see the column names by using the \"names()\" function to print a character vector of the column names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Getting the column names using the names function\n\nnames(titanic_data)\n```\n:::\n\n\nWe will need to do some work on these to remove the use of capitalisation and spaces. \n\n\n## Cleaning Column Names\n\n### The Janitor Package\n\nThe **janitor** package offers many functions used to manipulate data, such as finding duplicates. In this chapter we will use it to clean column names. \n\nThe function to use is called \"clean_names()\" and automatically formats the column names as **snake_case**, but this can be altered with an additional parameter.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean the column names and overwrite the variable\n\ntitanic_data <- clean_names(titanic_data)\n\n# Getting the column names of the dataset\n\nnames(titanic_data)\n```\n:::\n\n\n\n# The Data Manipulation Package dplyr \n\nThis is one of the most powerful packages in the **tidyverse**, which makes data manipulation simple and code easy to read.\n\nWe will look at how to perform the following actions:\n\n1. arrange/sort\n2. select\n3. filter\n4. mutate\n5. joining data\n\nwith the aim of the package to provide a function for each basic **verb** of data manipulation. This has led to them being referred to as such in the documentation. \n\nEach of the verbs have the same structure:\n\n> **verb(.data, info,....)**, note the full stop which is syntax to allow us to reference variables from the dataset (enables auto-completion too!)\n\nand the [cheat sheet](https://nyu-cdsc.github.io/learningr/assets/data-transformation.pdf) is incredibly useful for a reference piece. \n\nBefore we jump into the verbs, let's see dplyr's version of renaming columns!\n\n\n## Rename\n\nWe may wish to remain within the tidyverse when cleaning column names (say, Janitor is not available to you), which invites the use of **rename()**.\n\nThis allows you to change column names one at a time using the following syntax:\n\n> **rename(.data, new_name = old_name)**\n\nAs an example, let's rename the age_of_passenger column to simply \"age\". \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rename the age_of_passenger column to age\n\nrename(.data = titanic_data,\n       age = age_of_passenger)\n```\n:::\n\n\nIf we glimpse the data again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Take a peak at titanic data\n\nglimpse(titanic_data)\n```\n:::\n\n\nWe see that age has not carried through to the underlying dataset.\n\nThis is an excellent feature of the tidyverse, in that if we do not:\n\n* Directly overwrite the variable \n* Or create a new one using assignment **<-**\n\nthen it just shows us what that process will do, so we can then make the decision on whether it's what we want. \n\n\n### Renaming multiple columns\n\nOne of the best things about dplyr's functions is that the .data argument clues the function in to the columns themselves, which means we can just continually list them, or make changes to them, without wrapping them in a vector **c()**, like many other libraries. \n\nAs an example, let's create a new variable and rename the \"of_passenger\" columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rename of_passenger columns and create a new variable\n\ntitanic_renamed <- rename(.data = titanic_data,\n                       name = name_of_passenger,\n                       sex = sex_of_passenger,\n                       age = age_of_passenger) # Notice autocompletion\n\nglimpse(titanic_renamed)\n```\n:::\n\n\nWe also didn't need to give them in the order specified either, the function automatically knows what columns we are referring to in the underlying dataset.\n\nThere is much more we can say about the structure of these functions, but we will see this as we proceed through the verbs themselves. \n\n\n## Arrange\n\nOur data is displayed in the same order as the source data.\n\nWe may want to sort our data based on specific columns. \n\nTo do so, we use the verb **arrange()**. \n\n### Example - Single column sort\n\nFrom here, we will only create a new variable or overwrite the existing one when a change we wish to permanently keep is performed. \n\nWe highly encourage you to do the same, as creating multiple new variables you will never use again will clutter up your environment. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort titanic by fare\n\narrange(.data = titanic_data,\n        fare)\n```\n:::\n\n\nWe get a larger output here that does not show us all columns at a glance, so checking that the outcome is what we expect is more difficult.\n\nWe should instead use **glimpse()** to check the output, which needs to be written first in the code. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by fare and then glimpse\n\nglimpse(arrange(.data = titanic_data,\n                fare))\n```\n:::\n\n\nNotice that by default, arrange() sorted the fare column in **ascending** order.\n\n### **Small Aside - Functions**{-}\n\nNotice that glimpse() is **written first** but **executed last**, since R evaluates functions from the inside out.\n\nAfter all, if glimpse() has no input, we can't see anything at all! \n\nKeep this in mind as it will become very important later.\n\n\n### Example - Desending Order Sort\n\nTo sort a column in descending order, we use the **desc()** function and the column name as its input. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort titanic in descending order \n\nglimpse(arrange(.data = titanic_data,\n                desc(fare))) \n```\n:::\n\n\n### Example - Multi-Column Sort\n\nWe can also sort by multiple columns, but this creates a chain of **dependence**, in that the first column sort is maintained before the second sort is performed. \n\nThis means that the second sort won't change the order from the first sort.\n\n* When this becomes useful is if there are numerous examples of the same value, such as the 0.0000 values in the fare column.\n    * Whilst the position of 0.0000 will not change, the values in the adjacent column will be sorted. Some of those paying £0 fare may have been younger than others, after all. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Multi-column sort\n\nglimpse(arrange(.data = titanic_data,\n                fare,\n                age_of_passenger))\n```\n:::\n\n\nNotice that we were able to just continually reference columns from the data as if they were arguments to the function, and the verb understands that immediately, just like with rename().\n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\nSort the titanic data set by age in **descending** order, then fare in **ascending** order. \n\nGlimpse the result.\n\n### **Show Answer**{-}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by age desc, fare asc\n\nglimpse(arrange(.data = titanic_data,\n                desc(age_of_passenger),\n                fare))\n```\n:::\n\n:::\n\n\n## Select\n\nSometimes we will want to work with smaller tibbles that contain just a subset of available columns.\n\nThe **select()** verb is perfect for this, and it takes the arguments:\n\n* The first is our dataset, made even simpler with \".data\"\n* From here we list as many columns by name as we would like to be retained in our selecting process.\n    * The order in which we specify them is the order they will be in the smaller tibble.\n\n### Example - Single Column\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting data\n\nglimpse(select(.data = titanic_data, \n                name_of_passenger))\n```\n:::\n\n\nNotice that this has returned a tibble with one column, not the underlying vector itself that **$** would have.\n\n### Example - Multiple Columns\n\nIf we want to select multiple columns, we can continue to list them, separating with commas, as we did with **arrange()**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting data\n\nglimpse(select(.data = titanic_data,\n                name_of_passenger, \n                age_of_passenger,\n                pclass))\n```\n:::\n\n\n\n### Example - Columns in a range\n\nWe can select consecutive columns (next to one another) with the syntax we used for indexing in chapter 2, the colon **:** operator.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting from passenger class to the age of passenger in order\n\nglimpse(select(.data = titanic_data,\n                pclass:age_of_passenger))\n```\n:::\n\n\nNotice that we return the columns from pclass to age_of_passenger in the order of the source data. \n\n\n### Selecting with exclusion\n\nUp to this point we have selected with **inclusion**, a.k.a we specify the columns we want to include in our smaller tibble.\n\nThe real power of select comes from it's flexibility, in that we can reduce the amount of code to write by using **exclusion** instead, a.k.a specify the columns we don't want to include.\n\nSay we want to keep 7 of 9 columns, instead of typing out the names of all 7, we can just exclude the 2 we don't want instead. \n\n### **Example**{-}\n\nTo exclude, we use the minus sign operator **-** which signifies \"do not select this\" or \"select, not this\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting by excluding columns we don't want\n\nglimpse(select(.data = titanic_data, \n                               -name_of_passenger, \n                               -age_of_passenger, \n                               -pclass))\n```\n:::\n\n\nThere is an even more streamlined way to do this, by wrapping the columns in a vector with the **c()** function and using one minus sign outside it.\n\nYou can think of this as expanding brackets in mathematics:\n\n> \\-c(col1, col2) = c(\\-col1, \\-col2) = \\-col1, \\-col2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using a vector for exclusion\n\nglimpse(select(.data = titanic_data, \n                               -c(name_of_passenger, \n                                  age_of_passenger, \n                                  pclass)))\n```\n:::\n\n\n\n### Selecting with Index Position\n\nWe can also select the columns using their index position, starting from 1, just like we did with data structures in chapter 2.\n\nLet's select columns 1 to 4, and also column 7.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting sequential and out of sequence columns with index position\n\nglimpse(select(.data = titanic_data, \n                               1:4, \n                               7))\n```\n:::\n\n\nExclusion works similarly here with the minus sign.\n\nNote that whilst this may be required in some cases, it is usually better to be **explicit** with the exact column names, if possible. \n\n\n### Select Helper Functions\n\nAs if **select()** wasn't already helpful enough, it even has helper functions that allow us to select on specific patterns, such as a prefix or suffix in a column name. \n\nThey are as follows:\n\n* starts_with(match): Starts with a prefix.\n* ends_with(match): Ends with a suffix.\n* contains(match): Contains a literal string.\n* matches(match): Matches a [regular expression](https://www.regular-expressions.info/quickstart.html).\n* everything(): Selects all variables.\n* last_col(): Selects the last column.\n\n\nThese can be passed instead of column names **and** alongside selected column names as well. \n\n### **Examples**{-}\n\nLet's return columns that start with an \"s\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting columns\n\nglimpse(select(.data = titanic_data, \n               starts_with(\"s\")))\n```\n:::\n\n\nAs a second example, let's return everything.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting everything\n\nglimpse(select(.data = titanic_data,\n               everything()))\n```\n:::\n\n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\n\n1. Select the second, third and fourth columns from titanic_data, without typing all three.\n\n\n2. Select all columns except \"fare\", \"cabin\" and \"embarked\" from titanic_data. Note that these are consecutive.\n\n\n3. Select just the last column from titanic_data using a helper function.\n\n\n4. Select the columns that end in the suffix \"passenger\" using a helper function.\n\n\n### **Show Answer**{-}\n\n1. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Select second, third and fourth column\n\nglimpse(select(.data = titanic_data, \n                survived:sex_of_passenger))\n```\n:::\n\n\n2. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Using exclusion on a range\n\nglimpse(select(.data = titanic_data, \n               -fare:-embarked))\n\n# OR\n\n# glimpse(select(.data = titanic_data,\n#                -c(fare, cabin, embarked)))\n\n# OR\n\n# glimpse(select(.data = titanic_data,\n#                -fare,\n#                -cabin,\n#                -embarked))\n```\n:::\n\n\n3. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting last column only\n\nglimpse(select(.data = titanic_data,\n               last_col())) \n```\n:::\n\n\n\n4.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting on a suffix\n\nglimpse(select(.data = titanic_data,\n               ends_with(\"passenger\"))) \n```\n:::\n\n:::\n\n\n## The Pipe Operator \n\nUp until now, we have run verbs one at a time on our dataset, be it to sort or select columns. \n\nThe real power of the tidyverse comes from the ability to chain these functions together in a sequence for more complex data manipulation tasks. \n\nHowever, out of the box, this becomes laborious quickly due to the nature of functions. \n\n### Returning to Functions - Composition\n\nAs we saw earlier with glimpse(), to apply many functions to a single output, known as **composition** of functions, we must nest them, with the function applied last being written first, and evaluated from the inside to the outside.\n\n### **Example**{-}\n\nFor example, let's take the **sqrt()** and **round()** mathematical functions and apply them together, so that we obtain the square root of a number and hence round it to a specified number of decimal places.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compose mathematical functions\n\nround(sqrt(2))\n```\n:::\n\n\nNotice that the functions are evaluated in reverse order (from the inside, out) just as you would with writing this mathematically. You would perform the square root operation first, **then** round the result. \n\nShould we wish to use an extra parameter, we need to start thinking about the brackets, as they are the opening and closing doors of a function itself.\n\nThus, the **digits** parameter needs to go inside the round() brackets, not the sqrt() ones.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compose mathematical functions with extra parameters\n\nround(sqrt(2), digits = 2)\n```\n:::\n\n\nNotice that the input to the function round() was the output from the sqrt() function. \n\n\n### Composition of functions in the tidyverse\n\nThis becomes tricky to comprehend when working with the tidyverse functions, as we are effectively performing actions in sequence, such as selecting the columns we want and **then** sorting the result. \n\nAs such, the output of one function is the input to another:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select passenger columns and fare then arrange by fare\n\nglimpse(arrange(.data = select(.data = titanic_data,\n                                ends_with(\"passenger\"),\n                                fare),\n                desc(fare)))\n```\n:::\n\n\nNotice that the input to arrange was the result of a select operation, so we had to keep track of our brackets and ensure that the desc(fare) was placed within arrange(), **not** select().\n\nGoing forward, we will see more verbs that can be applied on top of this, and it becomes difficult to manage. \n\nThis is where the pipe operator comes in.\n\n\n### Introducing the Pipe\n\nThe Pipe Operator makes it possible to chain a sequence of functions starting with the base data as an input to the sequence.\n\nThis removes the need to type the **.data** argument each time. \n\n* Prior to R 4.1, the pipe operator came from a package known as **magrittr**, which would be loaded alongside the tidyverse, and it took the form **%>%**.\n\n* From R 4.1 onwards, the operator comes as standard with base R, as it has become the universal standard for data analysis. It now takes the form **|>**, and this option must be turned on in the Tools --> Global Options tab. \n\n![](Images/native_pipe.png){fig-alt=\"The Code, Editing pane with the native pipe operator tick box.\"}\n\nThe shortcut for this operator is **CTRL + SHIFT + M** and is one you will use alot from here on. \n\n### **Example - Single Value**{-}\n\nLet's return to our square root and rounding functions. Let's apply one, and then both in sequence using our new operator.\n\n* First, we write the value or dataset we wish to apply functions to, it is at the entrance to the \"pipe\" if you will. \n* Then, we write the function we wish to use and any additional parameters we may need. \n* The pipe operator **passes** the input to the function, so we do not need to write it within the brackets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Our first pipe - with a single value\n\n2 |> sqrt()\n```\n:::\n\n\nYou can read the pipe operator as **AND THEN**. \n\nIt takes the output of one function AND THEN uses that as the input of the next function, and so on. \n\nThis means that to chain a sequence of functions, we will use the pipe operator again to pipe our output to our next function as its input. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Our first sequence of pipes\n\n2 |> sqrt() |> \n     round(digits = 2)\n```\n:::\n\n\nThis is quite the shift from what we have done so far, but is more readable in plain english: \n\n>**To the value 2, apply the square root function, and then, round that output to 2 decimal places.**\n\nNotice, that following the second pipe, we insert a new line, which automatically moves us in a few spaces. This is optional but is easier to read as a sequence.\n\n\n### Using the Pipe Operator with the tidyverse\n\nWhat was done above was an oversimplification of why the pipe was created, in reality it was created to pipe datasets into functions, as opposed to a single value. \n\nEven in the case of datasets, we do not need to pipe if we are only applying a single function such as glimpse().\n\nIt is when we are performing a chain of steps that the pipe completely simplifies our code, enhacing readability.\n\n\n### **Example**{-}\n\nLet's return to our previous example, where we selected passenger demographics and sorted by fare. \n\n* First, we write the dataset we want to apply this sequence of steps to.\n* AND THEN pipe that into the **select()** function, specifying what columns we wish to retain.\n* AND THEN pipe that output to the **arrange()** function, so that it can be sorted by whatever column(s) we wish.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Repeat earlier operation with pipes\n\ntitanic_data |> \n    select(ends_with(\"passenger\"),\n           fare) |> \n    arrange(desc(fare))\n```\n:::\n\n\nThis way, the code is written in the order that it executes, as opposed to the reverse order without the pipe operator. \n\n>**To the titanic dataset, we select columns that end with \"passenger\" as well as the fare column, and then, sort that in descending order of fare paid.**\n\nWe could also pipe the output to a glimpse() for easier sense checking.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pipeline with glimpse\n\ntitanic_data |> \n    select(ends_with(\"passenger\"),\n           fare) |> \n    arrange(desc(fare)) |> \n    glimpse()\n```\n:::\n\n\n\n### **Variables with tidyverse chains**{-}\n\nNotice that we didn't create a variable in the prior conversion.\n\nThis is because it can cause confusion between the assignment operator **<-** and the pipe operator **|>** if not covered separately. \n\nIn front of the previous sequence, known as a **pipeline**, we would write our variable name and assignment operator, which saves the final output in memory.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save pipeline as a variable \n\ntitanic_demographics_sort <- titanic_data |> \n    select(ends_with(\"passenger\"),\n           fare) |> \n    arrange(desc(fare))\n\n\ntitanic_demographics_sort |> \n    glimpse()\n```\n:::\n\n\nBe careful not to confuse the meaning of the two operators, this will take some practice to get used to. \n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\nSpeaking of pratice, let's try out our new tool!\n\nCreate a pipeline that:\n\n* Selects the first five columns of the data\n* Arranges them in ascending order of age.\n\nAssign this output to a new variable and glimpse it.\n\n\n### **Show Answer**{-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecting and ordering by age with pipes\n\ntitanic_age_sort <- titanic_data |> \n    select(pclass:age_of_passenger) |> \n    arrange(age_of_passenger)\n\ntitanic_age_sort |> \n    glimpse()\n```\n:::\n\n\n:::\n\n\n## Filter\n\nOften, we are only interested in groups of rows that adhere to a specific condition, such as:\n\n* Passengers that paid over or under a certain fare.\n* Passengers who are in a particular age threshold.\n* Passengers who embarked from a particular port.\n\nand of course, combinations of the above.\n\nThe next verb, **filter()** allows us to subset our rows in this way. To understand this section, we first need to consider conditions.\n\n\n### Conditional Statements\n\nA conditional statement is one that returns **TRUE** or **FALSE** dependent on the outcome. \n\nWe saw examples of these back in Chapter 1, when we were producing logicals with comparisons. For example:\n\n* 4 < 5 is a condition statement that evaluates to TRUE\n* 4 != 4 is a conditional statement that evaluates to FALSE\n\nLogical Operator| Description\n:--------------:|:------------:\n        <       | Less Than\n       <=       | Less Than or Equal To\n       \\>       | Greater Than\n       >=       | Greater Than or Equal To\n       ==       | Equal To\n       !=       | Not Equal To\n       \\|       | Or\n        &       | And\n        !       | Not\n      any()     | Checks if any value in a logical vector are TRUE\n      all()     | Checks if all values in a logical vector are TRUE\n      is.na()   | Is the value missing (NA)?\n      between() | Is between 2 numbers\n\n\n>**Note: The \"!\" allows us to flip or invert an expression. Basically, if an expression returns c(TRUE, TRUE, FALSE), the inverted expression (place ! in front of it) will return c(FALSE, FALSE, TRUE).**\n\nThese statements can of course be much more complex than comparing two single numbers, we can apply them across columns with dplyr's **filter()** verb! \n\n\n### Single Conditional Filtering\n\nWe will first look at filtering by a single condition, which are constructed as follows:\n\n* We begin with the column to compare with.\n* Next is the logical operator of choice, such as **<**, **>**.\n* Last up is the value to compare each entry in the column to, which generates the set of TRUEs and FALSEs.\n\nThis is generated in the background, and **filter()** will keep only the rows that return **TRUE** from this comparison. \n\n> **For example, to subset down to only second class passengers, we would write: \"pclass == 2\".** \n\n### **Example - Categorical**{-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to retain only second class passengers\n\nsecond_class <- titanic_data |> \n    filter(pclass == 2) |> \n    glimpse()\n```\n:::\n\n\nA quick way to check that the filter has worked is to use base R's **unique()** function on the column. \n\nWe need to use our **$** here to reference columns by name as this is not a tidyverse method.\n\nLet's check the original data first.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Return unique values from the original data\n\nunique(titanic_data$pclass)\n```\n:::\n\n\nWe see that the pclass column has 3 unique levels of 1, 2 and 3.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Return unique values from the filtered data\n\nunique(second_class$pclass)\n```\n:::\n\n\nWe see that in the filtered data, we have just second class passengers, as expected. \n\n### **Example - Numeric**{-}\n\nLet's filter to passengers who paid above £200.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select passengers who paid more than 200\n\ntitanic_data |> \n    filter(fare > 200) |> \n    glimpse()\n```\n:::\n\n\nNotice that we didn't save this as a variable, as this was just an example, one we will not carry forward in our analysis. \n\nHowever, if you are being asked to answer specific questions, then saving the outputs of your manipulation pipelines as variables is very useful, to prevent overwriting the base data.\n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\n1. Use filter to return the row for the passenger named: 'Birkeland, Mr. Hans Martin Monsen'\n\n2. Filter for passengers that are male and save it as a variable. Can you count how many there were?\n\n3. Filter for passengers that are under 18 years of age and save it as a variable. Can you count how many there were?\n\n4. **Extension - Harder**: What percentage of passengers in the dataset survived? Remember, to compute a percentage, we must multiply the proportion by 100. \n\n\n### **Show Answer**{-}\n\n1. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Filtering to a specific passenger\n\ntitanic_data |> \n    filter(name_of_passenger == \n               'Birkeland, Mr. Hans Martin Monsen') |> \n    glimpse()\n```\n:::\n\n\n2. \nTo display the number of males in the filtered data, we simply need the number of rows, the length of the data!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Males only\n\ntitanic_male <- titanic_data |> \n    filter(sex_of_passenger == 'male')\n\n# Counting the number of males\n\nnrow(titanic_male)\n```\n:::\n\n\n3. \nTo display the number of passengers below 18 years of age in the filtered data, we simply need the number of rows, the length of the data!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Underage passengers \n\ntitanic_underage <- titanic_data |> \n    filter(age_of_passenger < 18)\n\n\n# Counting the number of underage passengers\n\nnrow(titanic_underage)\n```\n:::\n\n\n4. \nFirstly, we need to filter the dataset to those who survived, and the percentage would be calculated as:\n\n> Number of those who survived/Number of passengers as a whole * 100\n\nRemember, we can compute the number who survived and the number of passengers, we just need the number of rows in each subsequent tibble.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Passengers who survived\n\ntitanic_survived <- titanic_data |> \n    filter(survived == 1)\n\n# Survival percentage\n\n(nrow(titanic_survived) / nrow(titanic_data)) * 100\n```\n:::\n\nSo we see that, tragically, only 38% of the passengers aboard the titanic survived.\n\n:::\n\n\n### Multiple Conditional Filtering \n\nWe have thus far filtered on conditions for a single column, but there is no reason we can't use multiple conditions to filter by several conditions and/or columns at once. \n\nFor example:\n\n* We want **male** passengers who **survived**.\n* We want **over 18** passengers who embarked from **Southampton**.\n\nHowever, we do need to think about how the conditions relate to each other.\n\n\n### **Relationships between conditions**{-}\n\nThere are two ways we can combine conditions together:\n\n* **AND** relationships are given by the **&** symbol. \n    * This implies both/all conditions must be met for a row to evaluate to TRUE before the filter is applied.\n    \n* **OR** relationships are given by the **|** symbol. \n    * This implies that if any of the conditions can be met (one or more) a given row evaluates to TRUE before the filter is applied.\n\n> This does mean that combinations of TRUE and FALSE conditions can lead to different outputs with AND/OR relationships. This is summarised in the table below.\n\n| Condition 1 | Condition 2  | AND Equates to     | OR Equates to      |\n|:-----------:|:------------:|:------------------:|:------------------:|\n|     True    |     True     |        True        |        True        |\n|     True    |     False    |        False       |        True        |\n|    False    |     True     |        False       |        True        |\n|    False    |     False    |        False       |        False       | \n\n\n### Examples\n\nFor our first example, let's filter to first class, female passengers. \n\nThis is an AND relationship, as they must be first class and female. Thus, any row that does not satisfy both of these conditions will be filtered out in the process. \n\nRemember that AND combinations are very strict, so ensure that the loss of a possibly large amount of data is appropriate for your analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to first class female passengers\n\ntitanic_data |> \n    filter(pclass == 1 & sex_of_passenger == \"female\") |> \n    glimpse()\n```\n:::\n\n\nFor our next example, let's select passengers who were male **OR** adults (over 18). \n\nThis means that males under 18 will be kept and adult females will also be kept, as only one of the conditions needs to be true to be retained by filter!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to males or adults\n\ntitanic_data |> \n    filter(sex_of_passenger == \"male\" | age_of_passenger > 18) |> \n    glimpse()\n```\n:::\n\n\n\n### Special Cases of AND/OR\n\nWhilst the above conventions are easy to read from left to right, when constructing much more complex chains of conditions, it becomes laborious quickly. \n\nTo alleviate this, dplyr has some special functions that allow us to streamline cases of numerous conditions on the **same** column.\n\n\n### **The between() function**{-}\n\nFirst is the **between()** function, which is similarly to an and relationship for conditions on numeric columns.\n\nIt allows us to specify:\n\n* An upper bound for the value in the column, a.k.a the value for which it should not be larger than or equal to.\n* A lower bound for the value in the column, a.k.a the value for which it should not be smaller than or equal to.\n\n> For example, between(3.5 and 7.5) will retain values greater than or equal to 3.5 and less than or equal to 7.5.\n\nLet's filter to those that paid between £250 and £500 for their tickets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to those that paid between two values\n\ntitanic_data |> \n    filter(between(fare, left = 250, right = 500)) |> \n    glimpse()\n```\n:::\n\n\nWhich is equivalent to saying:\n\n> filter(fare >= 250 & fare <= 500)\n\nOf course, we can combine this with other conditions across columns as well. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter tho those that paid between ?250 and ?500 who were female\n\ntitanic_data |> \n    filter(between(fare, left = 250, right = 500) & \n                   sex_of_passenger == \"female\") |> \n    glimpse()\n```\n:::\n\n\n\n### **The %in% function**{-}\n\nSecondly is the **%in%** function, which checks for membership of the column value in a vector of options we provide. \n\nThis is similar to an OR relationship, as it allows us to bring through multiple values from a column.\n\nLet's filter to capture those that embarked from Southampton or Cherbourg.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to those that embarked from S or C\n\ntitanic_data |> \n    filter(embarked %in% c(\"S\", \"C\")) |> \n    glimpse()\n```\n:::\n\n\nWe can check with **distinct()** whether this accomplished what we were looking for.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter to those that embarked from S or C and check\n\ntitanic_data |> \n    filter(embarked %in% c(\"S\", \"C\")) |> \n    distinct(embarked)\n```\n:::\n\n\nThis process would be equivalent to performing:\n\n> filter(embarked == \"S\" | embarked == \"C\") \n\nand is incredibly useful for larger categorical variables we wish to trim. \n\nAs with between(), we can also combine this with other conditions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select passengers embarking from S or C that were male\n\ntitanic_data |> \n    filter(embarked  %in% c(\"S\", \"C\") &\n           sex_of_passenger == \"male\") |> \n    glimpse()\n```\n:::\n\n\n### Negating Conditions\n\nWe can also use the negation operator **!** to reverse the outcome of the condition. \n\nThis is useful for cases where exclusion is quicker than typing out conditions for inclusion. \n\nSay for example you have a categorical variable with 9 unique categories.\n\nYou are interested in filtering so that only 8 of the categories remain. Instead of chaining **OR** conditions together, you can instead write the condition that would return **just** that one, and negate it to remove it instead.\n\n### **Example**{-}\n\nLet's see this in action by negating the statement to select passengers who embarked from Southampton, \n\nThis is the opposite of writing out filters to retain Cherbourg and Queenstown. \nThis is a great time saving measure for larger datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use negation to filter down to passengers embarking from Cherbourg or Queenstown\n\ntitanic_data |> \n    filter(!embarked == \"S\") |> \n    distinct(embarked)\n```\n:::\n\n\nThis is, of course equivalent to using the not equal **!=** comparison in such a simple case:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter for passengers who did not embark from Southampton\n\ntitanic_data |> \n    filter(embarked != \"S\") |> \n    distinct(embarked)\n```\n:::\n\n\n### **Example - AND/OR Negation**{-}\n\nOf course, if you negate and **and**/**or** relationships:\n\n* Not only is each individual condition negated\n* The and/or is reversed to or/and respectively\n\nThis comes from logical statements in mathematics, specifically, De Morgan's laws.\n\n![](Images/demorgans_law.png){fig-alt=\"Negating a combined statement negates each individual statement, as well as the logical operator combining them.\"}\n\nLet's take an example we we required those that embarked from Southampton or paid above £100 in fare.\n\nMathematically speaking, if we negate this condition, we get:\n\n> **!(southampton OR > 100 fare) = (!southampton AND !>100 fare)**\n\nIt is recommended to wrap your OR/AND condition in brackets, to ensure the negation is carried throughout. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Harder example\n\ntitanic_data |> \n    filter(!(embarked == \"S\" | fare > 100)) |> \n    distinct(embarked)\n```\n:::\n\n\nWe see that we have indeed negated the selection of Southampton, as expected.\n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\n1. Filter so that only second or third class passengers are included in the data. \n\n2. Filter so that only passengers who travelled alone are included in the data. How many were there?\n\n\n3. **Extension Exercise** - What percentage of passengers who embarked from Cherbourg or Queenstown and paid a fare between £100 and £350 survived? \n\n\n### **Show Answer**{-}\n\n1. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter for second or third class passengers\n\ntitanic_data |> \n    filter(pclass  %in% c(2, 3)) |> \n    glimpse()\n```\n:::\n\n\n\n2. \nFor those travelling alone, their sibsp and parch values should be 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filtering for passengers travelling alone\n\nlone_passengers <- titanic_data |> \n    filter(sibsp == 0 & parch == 0) |> \n    glimpse()\n\n# How many there are\n\nnrow(lone_passengers)\n```\n:::\n\n\n3. \nThis is a multi-stage problem, so we must filter for the required conditions (saving it to a variable), then compute the percentage.\n\nSince we need all of these conditions to be TRUE, we must use **&** to combine them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter for those that embarked from C or Q, paid certain fare and survived\n\ncherb_queens_survivors <- titanic_data |> \n    filter(embarked %in% c(\"C\", \"Q\") &\n           between(fare, left = 100, right = 350) &\n           survived == 1)\n\n# Compute final percentage\n\nround((nrow(cherb_queens_survivors) / nrow(titanic_data)) * 100, digits = 2)\n```\n:::\n\n:::\n\n\n## Mutate\n\nWhen cleaning and transforming data, we often want to apply changes at the column level, such as:\n\n* Converting to lower case/any character work\n* Rounding to a specified number of dp\n* Converting the datatype\n* Combine columns into ratios/proportions - known as **calculated columns **\n\nTo accomplish all of the above, we need our next verb, **mutate()**. To create a new column, we use the following syntax:\n\n> **mutate(new_column_name = contents_of_column)**\n\n\n### Constant Value Variables\n\nThe simplest example would be adding a constant column, which contains the same value all the way down. \n\nWhilst the applications of this are minimal, it is the best first example for understanding mutate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add a constant character column\n\ntitanic_data |> \n    mutate(character_col = \"two\") |> # Column filled with the string \"two\"\n    glimpse() \n```\n:::\n\n\nAs another example, let's add a numeric constant column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add a constant numeric column\n\ntitanic_data |> \n    mutate(numeric_col = 3.14) |> # Column of pi\n    glimpse()\n```\n:::\n\n\n### Modifying existing variables\n\nThe mutate function is incredibly smart, as it allows us to apply functions to an entire column, with each cell transformed in turn.\n\nFor example, should we wish to make the name of passenger column lower case, we can use the **str_to_lower()** function from **stringr**. \n\nTo apply a function to an existing column:\n\n> **mutate(existing_column = function(existing_column,..))**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert names column to lower case\n\ntitanic_data |> \n    mutate(name_of_passenger = str_to_lower(name_of_passenger)) |> \n    glimpse()\n```\n:::\n\n \nAnother example might be to round the age column to the nearest whole number, which could allow for conversion to an integer.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Round the age column to the nearest whole number\n\ntitanic_data |> \n    mutate(age_of_passenger = round(age_of_passenger)) |> \n    glimpse()\n```\n:::\n\n\nThis has the unexpected consequence of rounding the passenger with an age of 0.1667 (around 2 months) to 0, which makes no sense given the context. As such, it may be better to round to 2 decimal places.\n\nLet's do the same thing to the fare column as well, since money in GBP (£) is presented as two decimal places.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Round the fare column to 2 decimal places\n\ntitanic_data |> \n    mutate(fare = round(fare, digits = 2)) |> \n    glimpse()\n```\n:::\n\n\nNotice that we have forgotten something, as age still has 4 decimal places.\n\n### **Exercise**{-}\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\nIdentify the mistake we have made when converting existing columns and fix this mistake so that we permanently update them.\n\n### **Solution**{-}\n\nWe did not overwrite and reassign the titanic_data variable, we just observed the changes without permanently making them. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Round the fare and age columns to 2 decimal places\n\ntitanic_data <- titanic_data |> \n    mutate(age_of_passenger = round(age_of_passenger, digits = 2),\n           fare = round(fare, digits = 2))\n\nglimpse(titanic_data)\n```\n:::\n\n\n:::\n\nOf course, this does not mean we should be overwriting titanic_data everytime, as often we are just overviewing a transformation and sense checking it.\n\n\n### Calculated Columns\n\nLet's see an example of creating a bespoke column by combining existing ones.\n\nHere we will create the family size of each person. To compute this we need:\n\n* The number of siblings or spouses on board (sibsp)\n* The numbr of parents or children on board (parch)\n* The person themselves, as they aren't factored in to sibsp or parch\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Determining family size per passenger\n\ntitanic_data <- titanic_data |> \n    mutate(family_size = sibsp + parch + 1) # Add 1 for the person themselves\n\nglimpse(titanic_data)\n```\n:::\n\n\n### Conditional Columns\n\nWe can also use conditions like when we filtered, to create a logical column of TRUEs and FALSEs. \n\nThese are very common and are often known as **binary flags**, as they denote whether a certain condition is attained or not.\n\nThis is structured as follows:\n\n> **mutate(new_col = (condition))** where the condition is \"column operator value\", such as \"fare < 200\". \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating a conditional column on whether passenger is female\n\ntitanic_data <- titanic_data |> \n    mutate(is_female = (sex_of_passenger == \"female\"))\n\nglimpse(titanic_data)\n```\n:::\n\n\nUsually we want binary flags in numeric form, as most models we supply our data to require numeric variables. \n\nThis means we need to convert TRUE and FALSE to their numeric representations of 0 and 1.\n\nWe can use complex functions for matching and converting to perform this step. In particular, the **case_match()** function, which takes the following form:\n\n> **case_match(column, value_to_change ~ new_value, value_to_change ~ new_value)**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recode is_female to numeric\n\ntitanic_data <- titanic_data |> \n    mutate(is_female = case_match(is_female,\n                                  TRUE ~ 1, # Convert instances of TRUE to 1\n                                  FALSE ~ 0)) # Convert instances of FALSE to 0\n\nglimpse(titanic_data)\n```\n:::\n\n\nYou may not have seen this notation before with the tilde **~**, this is known as a **formula** in R, where the right hand side is equivalent to the left hand side.\n\nThis is common convention in R, seen most with linear modelling to define the equation. See this [technical article on the tilde](https://medium.com/anu-perumalsamy/what-does-mean-in-r-18cecd1b223f#:~:text='~(tilde)'%20is%20an%20operator%20that%20splits%20the%20left,the%20set%20of%20feature%20variables.&text=In%20the%20above%20example%2C%20df,the%20columns%20wages%20and%20yearsEd.) for more information.\n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\nCreate a new column called \"fare_dollars\", which converts the fare from GBP (£) to USD (\\$). The current exchange rate as of January 2024 is:\n\n> **£1 = $1.27**\n\nEnsure that the column is rounded to 2 decimal places.\n\n### **Show Answer**{-}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create fare dollars and rounding the output\n\ntitanic_data <- titanic_data |> \n    mutate(fare_dollars = round(fare * 1.39, digits = 2))\n\nglimpse(titanic_data)\n```\n:::\n\n:::\n\n\n## Joining Data\n\nMuch of the information we need to answer questions of interest is featured across multiple smaller datasets, so we can **join** or **merge** them together for one cohesive dataset.\n\nWe do require something essential for this to be possible, however, a **column in common** such as a unique identifier or reference, such as:\n\n* NHS number, allowing for data linkage across the NHS.\n* Any account number allows for data linkage aross financial institutions.\n* Email, phone numbers, social media hangles allow for data linkage across social media and online shopping.\n* Addresses allow for spatial data linkage, for geospatial applications\n\n\n### **Naming Conventions for Join**{-}\n\nThe dplyr package has a family of functions for joins.\n\nThey take the form **type_join** where the prefix \"type\" denotes the type of join itself. \n\nA naming convention we must establish here is that of the tibbles themselves, namely:\n\n* The larger dataset, the one we just to join data to, is the **left tibble**.\n* The smaller dataset, the one we want to join to another, is the **right tibble**.\n\n### Types of Join\n\n* **inner_join** - A stricter join where only data common to both tibbles is retained.\n\n* **full_join** - All data from both tibbles is retained, matched up where possible.\n\n* **left_join** - All data from the left tibble is retained, and only matching rows are merged from the right tibble.\n\n* **right_join** - All data from the right tibble is retained, and only matching rows are merged from the left tibble. This is the inverse process of the left join.\n\nGraphically:\n\n![](Images/sql-joins.png){fig-alt=\"Venn diagrams for each of the prior examples, with the included data shaded.\"}\n\nThere are also Semi Joins and Anti Joins for filtering, which you can read about in Hadley Wickhams [R for Data Science Chapter 19](https://r4ds.hadley.nz/joins.html)\n\n\n### Examples\n\nJoins are best explored using examples of each type.\n\nWe will use 2 very small datasets that come with **dplyr** to build this up.\n\nThe first is band_members, which we must assign to a variable to save in the global environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmembers_data <- band_members\n\nmembers_data\n```\n:::\n\n\nThe second is band instruments, which seems to have some connection to the prior dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstruments_data <- band_instruments\n\ninstruments_data\n```\n:::\n\n\nThese data sets have one common column which is **name**, so we can join them to have both band and plays in the same dataset. \n\nLet's assume that members_data is the left dataset and instruments_data is the right.\n\nPre-empting what will happen based on the above venn diagrams:\n\n* John and Paul appear in both datasets, so will be retained for most common joins.\n* Mick only appears in the members_data, so may disappear with stricter joins.\n* Keith only appears in the instruments_data, so may disappear with stricter joins.\n\n\n### **Join Syntax**{-}\n\nThe join functions take numerous arguments, with the following being required:\n\n* x - the left tibble\n* y - the right tibble\n* by - the column to join on\n\nand take the form:\n\n> **type_join(x = left_tibble, y = right_tibble, by = join_col)** where we can pipe in the left_tibble.\n\n\n### **Inner Join**{-}\n\nStarting with the inner join, this will only retain rows common to both datasets, which would see Mick and Keith removed. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform an inner join on band members and instruments data.\n\nmembers_data |> \n    inner_join(y = instruments_data,\n               by = \"name\")\n```\n:::\n\n\nAs expected, we kept John and Paul, and now have another column of information about them!\n\n### **Full Join**{-}\n \nA full join retains all rows across both datasets, but this raises the question of what happens to the entry in the column that they aren't featured? i.e.\n\n* Mick has no plays entry\n* Keith has no band entry\n\nSimply, they are filled with **NA**, as they are missing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform a full join on instruments and band data\n\nmembers_data |> \n    full_join(y = instruments_data,\n              by = \"name\")\n```\n:::\n\n\nWe see that, indeed, Mick has no entry for plays and Keith has no entry in band.\n\n### **Left Join**{-}\n\nA left join retains all rows in the left tibble, and just the matching data in the right. This means Mick will come along with an **NA** in the plays column, but Keith will be lost entirely.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform left join on band and instruments data\n\nmembers_data |> \n    left_join(y = instruments_data,\n              by = \"name\")\n```\n:::\n\n\n### **Right Join**{-}\n\nA right join is the opposite of a left join, so we will retain all values in the right tibble, including Keith, but only matching data in the left tibble, which means we will lose Mick.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Right join on band and instruments data\n\nmembers_data |> \n    right_join(y = instruments_data,\n               by = \"name\")\n```\n:::\n\n\n\n### Matching columns with different names\n\nA very common problem that occurs when joining is matching columns being named differently.\n\nThis can sometimes be easily rectified with a **rename()**, but there will be cases where modifying the data in this way is not allowed. \n\nThis is where the **join_by()** function from dplyr comes in, providing us a way to specify that two differently named columns are indeed the same. \n\n### **Example**{-} \n\nHere we introduce the band_instruments2 data, which is similar to the former but with one key difference.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instruments data\n\ninstruments2_data <- band_instruments2\n\ninstruments2_data\n```\n:::\n\n\nThe name variable is called \"artist\" here.\n\nWithin join_by(), we must set the column names of note equal to each other, using:\n\n> **join_by(left_col_name == right_col_name)**\n\nLet's join together band_instruments2 with the members data, using the join_by() function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join columns with names that don't match\n\nmembers_data |> \n    full_join(y = band_instruments2,\n              by = join_by(name == artist))\n```\n:::\n\n\n\n### Binding Datasets\n\nAnother common way in which datasets are combined is by binding them, where one dataset is appended on top of the other either **row by row** or **column by column**.\n\nWith row binding: \n\n* Columns are matched by name automatically, so the positioning of them does not matter. \n* Missing columns will be filled with NA, so we must be careful of this.\n\nWith column binding:\n\n* Rows are matched by position, so the tibbles we bind absolutely **must** have the same number of rows, otherwise we will get an error.\n\n\n### **Binding Rows**{-}\n\nWe use the **bind_rows()** function from dplyr, which will widen the dataset by adding more entries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Row bind the instruments tibbles\n\ninstruments_data |> \n    bind_rows(instruments2_data)\n```\n:::\n\n\nSince instruments2 has the name variable and instruments has the artist variable, these are seen as independent, and hence filled with NAs since they don't match.\n\n\n### **Binding Columns**{-}\n\nWe use the **bind_cols()** function from dplyr, which will lengthen the dataset by adding more variables. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Column bind instruments 1 and 2\n\ninstruments_data |> \n    bind_cols(instruments2_data)\n```\n:::\n\n\nNotice that despite plays being a repeating column, it is binded as we asked, and differentiated by its position, with the second column being \"plays...2\" and the fourth being \"plays...4\".\n\n\n### **Why we bind**{-}\n\nWhen data is collected consistently, it is often in the same form, be that monthly, weekly, annually and so on. \n\nTo create a historic time series, data must be sequentially appended unless separate storage is required. \n\nThis is often part of an automated process where data is ingested and then appended onto the existing, larger, collected dataset. \n\n\n### Union()\n\nAnother very useful function is  **union()** which will stack the data vertically, but keep only the distinct (unique) rows. \n\nThis means that any duplicated rows that exist in the current tibble are not brought over in the process.\n\nHowever, this does **NOT** remove duplicated **values**, only entire duplicated rows in the combined data, an important distinction to make. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Band members and instruments\n\ninstruments_data |> \n    union(instruments2_data)\n```\n:::\n\n\nYou will see that this causes an error, because Union is very strict about it's combination, in that all columns must match. \n\nLet's create a small tibble with matching columns to test this out.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create new entries for instruments data\n\nartist <- c(\"Mick\", \"Bono\", \"Ringo\", \"John\")\n\nplays <- c(\"guitar\", \"guitar\", \"piano\", \"guitar\")\n\ninstruments3_data <- tibble(artist = artist, plays = plays)\n\ninstruments3_data\n```\n:::\n\n\nNow let's union this instruments2, who's columns match exactly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Union the instruments datasets\n\ninstruments2_data |> \n    union(instruments3_data)\n```\n:::\n\nNotice that John, who would have been duplicated in the combination, was removed as intended by union().\n\n\n# Summary \n\nWe covered alot of content around dplyr here, but the possibilities are nearly endless with this incredible data manipulation library.\n\nBy no means are you meant to remember and recall the above. Instead, what is most important is that you understand the problem you are trying to solve, and can use the resources here (or your own) to then solve it.\n\nNext up, we will look at aggregating data and obtaining summary statistics.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}