{
  "hash": "4d1ddee9c805f42ab0bb86e0b6d227a6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 3 - Importing and Exporting Data\"\nauthor: \"Government Analysis Function and ONS Data Science Campus\"\nengine: knitr\nexecute:\n  echo: true\n  eval: false\n  freeze: auto  # re-render only when source changes\n---\n\n\n\n\n> To switch between light and dark modes, use the toggle in the top left\n\n# Learning Objectives\n\n* Understand the importance of argument order in functions.\n* Have an understanding of what packages are.\n* Be able to load and install a package.\n* Be able to check package versions and R version.\n* Be able to import data from multiple formats.\n* Be able to inspect loaded data.\n* Be able to export data.\n* Be able to explore data.\n\n\n# Returning to Functions\n\nSo far we have seen many functions, such as:\n\n* sqrt()\n* round()\n* c()\n* list()\n\nYou should make it a habit to explore the help files when you are using a function for the first time so you know:\n\n* What required arguments there are.\n* What optional arguments there are.\n* What default arguments there are (some arguments have a value by default so we can exclude them without error). \n\nRecall that they follow the form:\n\n> **functionName(argument1 = value1, argument2 = value2, and so on)**\n\n\n## How functions work\n\nThe seq() function from chapter 2 is the perfect example to reinforce how functions work, as well as common pitfalls.\n\nLet's take a closer look at the help file for seq().\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Help doc for seq()\n\n?seq\n\n# or\n\nhelp(seq)\n```\n:::\n\n\n\n\n\n![](Images/seq_helpfile.png){fig-alt=\"Seq() function help file.\"}\n\n\n### Function help files\n\nEvery help file will have a series of sections describing what the function does. It is worth focusing on the description, the usage and especially the arguments first. \n\n**Description**\n\nFor example, in the help file for seq() under **Description**, it tells us it is a function to \"Generate regular sequences\". \n\n**Usage**\n\nWe can see that seq() takes the required arguments:\n\n* from (which is 1 by default)\n* to (which is 1 by default)\n* by (which is calculated by default)\n\nand the optional arguments:\n\n* length.out \n* along.with\n\n\n**Arguments**\n\nHere, we can find out what these arguments are:\n\n  - from, to: the starting and maximal end values of the sequence.\n  - by number: increment of the sequence.\n\n\n### Execution of function arguments\n\nWe used this function when creating vectors, here's a reminder.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating a sequence of numbers\n\nseq(from = 2, to = 6, by = 2)\n```\n:::\n\n\n\n\nLet's consider what happens instead when we **don't** specify the arguments, just their values.\n\n### **Example**{-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating a sequence of numbers - not specifying arguments\n\nseq(1,10)\n```\n:::\n\n\n\n\nThis has generated a sequence of numbers from 1 to 10. In this case we did not supply a value for by, so it took the default value, which in this case is 1.\n\nWhat if we flip 10 and 1 instead?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating a sequence of numbers\n\nseq(10,1)\n```\n:::\n\n\n\n\nSo it is clear that where we place the value is important, because arguments are resolved **by position**, in the order specified in the help documnentation.\n\nSo above:\n\n* In the first example, it is assumed that we want a sequence from  1 that goes to  10. \n* Then if we swap the numbers it is assumed we want to sequence from 10 that goes to 1. \n\nHowever, if we name the arguments **explicitly** using argument = value, the order we specify them does not matter. \n\nLet's see this in action:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Reversing arguments but using argument name\n\nseq(to = 10, from = 1)\n```\n:::\n\n\n\n\nYou can sometimes run into errors with more complicated functions by taking the arguments for granted. \n\nOften there are many optional arguments that are resolved (position wise) before the required ones.\n\n>**We would encourage you to specify the arguments and parameters as it makes your code easier to understand.**\n\n\n# Packages\n\nOur default R installation, often referred to as **base R** gives us a lot of functionality out of the box.\n\nIf we want to implore the newest methodologies, adopted by the wider R community, then we need to install packages to achieve this.\n\n>**Packages are a collection of functions, compiled code and sometimes data sets which are stored in a library of code within R.**\n\nIn order to use a package, we first need to install it:\n\n* R installs packages from [CRAN](https://cran.r-project.org/) **The Comprehensive R Archive Network.** that contains over 20,000 packages.\n\n* You can install packages from outside of CRAN (such as from [GitHub](https://github.com/)) with specific functions. Please be aware of the source and quality in these cases.\n\nYour department may have a slightly different way of installing packages, so clearing this up is a good port of call.\n\n\n## Installing Packages\n\nTo install a package, we use the code below for **each** new package. \n\n>**install.packages(\"package_name\", dependencies = TRUE)** where dependencies allows the install to also take into account other packages your chosen one needs to function correctly. \n\nDependent on your Operating System, another parameter is also recommended:\n\n* For windows, use **type = win.binary**.\n* For mac, use **type = mac.binary** (this may differ for Apple Silicon).\n\n>**Important**: You will only need to install packages once, you should either do this in the console, or comment out the line in your script where this is done. \n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\n1. Install the packages below using the **R console** one at a time.\n\n* tidyverse\n\n* janitor\n\nNote that tidyverse is a collection of R packages that follow the same programming paradigm, so will take quite some time to install. \n\n### **Show Answer**{-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Installing packages\n\ninstall.packages(\"tidyverse\", dependencies = TRUE, type = \"win.binary\")\n\ninstall.packages(\"janitor\", dependencies = TRUE, type = \"win.binary\")\n```\n:::\n\n\n\n\n:::\n\nSuccessful installation should finish with messages as below, sometimes interspersed with some warnings. \n\n```\n## package 'janitor' successfully unpacked and MD5 sums checked\n## \n## The downloaded binary packages are in\n##  C:\\Users\\bandai1\\AppData\\Local\\Temp\\Rtmpm0ZY69\\downloaded_packages\n```\n\n## Loading Packages\n\nThink of packages as owning a book; you purchase (install) the book once, and after that when you need to reference it you can pick it up off your bookshelf. \n\nIn R we call this **loading**, and you should always load packages at the very top of your script.\n\nTo load a package, use the code:\n\n>**library(package_name)** where the package name is not a string this time. \n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\nLoad the packages you installed in the prior exercise:\n\n* tidyverse\n\n* janitor\n\n### **Show Answer**{-}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading packages\n\nlibrary(tidyverse)\n\nlibrary(janitor)\n```\n:::\n\n\n\n\n:::\n\nThere is almost always some output we get when loading packages. Some options are:\n\n* **package \"X\" was built under R Version \"Y\"** - this states that your R version may be lower than the one the package was written using. This is not always an issue, but you should endeavour to remain updated with your software. \n\n* **The following objects are masked from \"package::package_name\":** - this arises when functions from your newly loaded package have identical names to either a function in base R, or from another outside package.\n    * As such, the package you loaded takes precedence, and it's function under that name will be used. \n    * You can get around this by using the syntax **package_name::function_name** as R will attempt to autofill the functions from that package, and there is no way to misconstrue what package the function comes from. \n\n\n## Checking Versions\n::: {.panel-tabset}\n\nReturning to the versions issue, we may have an older version of R than the one the package was built for.\n\n### **Check R Version** {-}\n\nWe can check R version by running this command.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# To check the version of R\n\nversion\n```\n:::\n\n\n\n\nYou can see that we are running 4.1.3\n\nIf your version is a little older, this is fine, but we **thoroughly** recommend versions 4.1 and above and discourage versions beginning with a 3.\n\nOlder versions, such as 3.6.3 (which is popular) are no longer supported by the creators, and will conflict with almost all training you will engage with whilst learning. \n\n\n### **Check Package Version**{-}\n\nUse the packageVersion() function with the package supplied as a string.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Checking the package version\n\npackageVersion(\"tidyverse\")\n```\n:::\n\n\n\n\nYou see that we have the up to date 2.0.0, this is backwards compatible with some older versions, but beware of argument name changes to functions.\n\nIf you are working collaboratively you should always check that you are all using the same versions of packages. \n\n\n### **Masked Objects**{-}\n\nOne of the masks at play with tidyverse is the **filter()** functions:\n\n* Base R has a filter() function to apply on time series.\n* Whereas dplyr (a tidyverse package for data manipulation) has a filter() function to select rows based on columns.\n\nThese both take very different parameters, so it is important to know what we have masked. After loading the tidyverse, it will assume we want to use the dplyr version of filter going forward. \n\nTo use the alternative we would need to type \n\n>**stats::filter()**\n\n:::\n\n\n# Tidyverse\n\nHere we will introduce the tidyverse, a collection of R packages that changed the way many work with R forever. \n\nThe packages in tidyverse share a common philosophy for data manipulation and exploration so they work well together. \n\nThis philosophy is that of Tidy Data, described first in the [seminal paper](https://vita.had.co.nz/papers/tidy-data.pdf) by Hadley Wickham, the tidyverse's creator. \n\n## Advantages of the Tidyverse\n\nThe tidyverse is:\n\n* Well documented. Each sub-library has its own website containing a 'cheat-sheet' and vignettes. We thoroughly recommend bookmarking these.\n\n* Well established in the R data science community, meaning common issues and queries are already answered on platforms such as [Stack Overflow](https://stackoverflow.com/questions/tagged/r).\n\n* Designed such that all sub packages follow a core 'philosophy' which encourages best practice. \n\n* Open-source software and free to use. As are the books written by the tidyverse creator Hadley Wickham. The highest recommendation we can make is [R for Data Science](https://r4ds.hadley.nz/). \n\n\n## Disadvantages of the Tidyverse\n\n* Like R, tidyverse can have a steep learning curve, and its reliance on functional programming can confuse beginners. \n\n* It is incredibly flexible, which makes it hard to determine which solutions to problems are the best.\n\n* Quite verbose (wordy), which can lead to long scripts. \n\n\n## Tidyverse Breakdown\n\nBelow is a list of the core packages in tidyverse to provide some awareness into what they make possible:\n\n* [readr](http://readr.tidyverse.org) - Data import\n* [tibble](https://tibble.tidyverse.org/) - Tibbles, a modern re-imagining of data frames\n* [tidyr](https://tidyr.tidyverse.org/) - Data Tidying\n* [dplyr](https://dplyr.tidyverse.org/) - General data anipulation\n* [stringr](https://stringr.tidyverse.org/) - String anipulation\n* [forcats](https://forcats.tidyverse.org/) - Factor variables \n* [ggplot2](https://ggplot2.tidyverse.org/) - Data Visualisation\n* [purrr](https://purrr.tidyverse.org/) - Functional Programming\n* [lubridate](https://lubridate.tidyverse.org/) - For dealing with dates and times - included in tidyverse 2.0.0 onwards. \n\n\n![](Images/tidyverse.png){fig-alt=\"Tidyverse workflow of import, tidy, transform/model/visualise and communicate.\"}\n\nThe first of the core packages we will delve into is **readr**, which deals with reading in data, and by extension **tibbles**, the excellent update to dataframes that the tidyverse provides. \n\nHowever, we need an understanding of the working directory beforehand.\n\n\n# Working Directory\n\nR has a powerful notion of the working directory. This is where R looks for files that you ask it to load, and where it will put any files that you ask it to save. \n\nWe often refer to this as the \"starting point\" when R looks for a file you specified the path for.\n\nThankfully, we are using an **R project**, which makes filepaths and directories reproducible, by ensuring everyone who opens the project has this set by default.\n\n>**If you are not using a project (we recommend you do) you will need to set your own working directory with the [setwd() function](https://www.geeksforgeeks.org/how-to-use-setwd-and-getwd-in-r/) that requires a full path to the directory to change it manually.**\n\n\n## Checking Working Directory\n\nThe getwd() function (get working directory) is ideal.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Getting the working directory\n\ngetwd()\n```\n:::\n\n\n\n\nIf you are inside the project created within these materials, you should have the same final step in the \"path\", that of the \"Course_content\" folder.\n\n> **In Windows file paths are specified using back slashes, but in R a backslash already has a meaning, so we use a forward slash or two back slashes instead.**\n\n\n# Reading in Data\n\nThere are a variety of ways of reading data into R, in this chapter we will look at reading data using the packages:\n\n* readr - loaded with tidyverse\n* readxl - installed with tidyverse, but loaded separately. \n\n\n## Readr\n\nThe package provides a fast and friendly way to read data from:\n\n* Comma Separated Value (csv) files\n* Tab Separated Value (tsv) files\n\nconverting them to **tibbles**, which are the required data structure in the tidyverse. \n\nLet's formally introduce them now.\n\n### Tibbles\n\nTibbles are data frames, but they tweak some older behaviours to make life a little easier, R is over 20 years old after all:\n\n* Tibbles complain more when variables do not exist - leads to easier error checking.\n* Tibbles don't change variable names.\n* Tibbles don't tweak variable types from the source data. \n\n**The key benefits of tibbles are:**\n\n* In addition to its name, each column reports its type.\n\n* The dimensions of the tibble are shown at the top.\n\n* Tibbles have a refined print method that shows only the first 10 rows, and all the columns that fit on screen. This makes it much easier to work with large data.\n\n\n### How readr works\n\nThis package reads in datasets we supply by using a **family of functions**, ones that have the same prefix.\n\n> **read_filetype()**\n\nThe most common, and one we will use throughout the course is **read_csv()**.\n\n### Considerations to make\n\n> Before importing your data you need to know:\n\n* Where it is stored?\n\n* What kind of file is it?\n\n* Are there missing values in the data?\n    * Missing values in R are denoted by **NA**.\n\nThe code will take the following form:\n\n>**data_name <- read_csv(file_path)**\n\nand readr will:\n\n* Assume the first row of your data is the headings of the columns.\n\n* Attempt to guess the datatype of columns, given their content. If a numeric column contains 99 doubles and one character, then the same coercion that happened with vectors will happen again (since columns are vectors) and we get a character column.\n    * One of the first data checks you should do is that the types of the columns match what you expect. \n\n\n### Example - Our first filepaths\n\nLet's load in the titanic dataset in the \"Data\" folder. \n\nWe need to figure out where this is and how to get there from our current working directory, so that we can tell R. \n\n::: {.panel-tabset}\n\n### **Absolute Filepaths**{-}\n\nAn **absolute** or full filepath is constructed as:\n\n>\"starting_drive/step_1/step_2/step_3/..../destination\"\n\nthis details the full path taken to reach the file.\n\nTo reach \"titanic.csv\" the absolute filepath for us is \n\n>\"C:/Users/marshj1/af_introduction_to_r/data/titanic.csv\"\n\nNote that your usernames and drives will differ to ours. \n\n### **Relative Filepaths**{-}\n\nA relative filepath is the path to reach the file **relative** to the current working directory. \n\nThus we are already part of the way there, and just need to tell R where to go from here:\n\n>\"working_directory/step_1/step_2/.../destination\"\n\nHowever, in our case, our working directory is one level deeper than we'd like to be, in the **course_content** folder.\n\n>To reach the dataset, we must exit this folder to get back to the root, then enter the data folder, and select **titanic.csv**\n\nTo do so, we need to know how to go back one folder level, or exit the current directory, this is written as **../** where the two full stops denote going back. \n\nAs such, the relative filepath we need to reach the dataset is\n\n>\"Data/titanic.csv\"\n\nVisually, to understand the tree-like folder structure, we have something like the following going on:\n\n![](Images/folder_structure.jpg){fig-alt=\"Top level is introduction to R, folders are at level 2, items in the folders are level 3.\"}\n\n### **Loading in the data**{-}\n\nLet's read in titanic using a relative filepath. \n\nWe simply need to go into the **data** folder, then select the **titanic.csv** file to load in.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in titanic with read_csv()\n\ntitanic_data <- read_csv(\"Data/titanic.csv\")\n```\n:::\n\n\n\n\nYou will get some information on:\n\n* rows and columns\n* Counts of each column datatype\n\n### **Inspect Data**{-}\n\nLet's call the name of the variable we have created to see the output of our first tibble.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Display the titanic data\n\ntitanic_data\n```\n:::\n\n\n\n\nNotice the refined print we get from this, that provides so much more information than the data frame output did in chapter 2. \n\nIt may take more time to read and understand, but prevents you from having to use many additional functions to find out things such as dimensions (rows and cols).\n\nAnother example of inspection is with View(), which opens a separate tab in the code editor pane with the dataset in spreadsheet form.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Viewing the data - Note the capital V\n\nView(titanic_data)\n```\n:::\n\n\n\n\n:::\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\n1. Having read in the titanic data above, have a look at the column Age of passenger.\n\n2. What type of data would you expect this column to be?\n\n3. Use the \"str()\" function to see the data type R has set it to be.\n\n\n### **Show Answer**{-}\n\n1. Have a look at the column Age of passenger.\n\n2. The column looks numeric.\n\n3. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using the str() function\n\nstr(titanic_data)\n```\n:::\n\n\n\n\nWe can see that R has classed the column as character because of the **.** and asterisk within it.\n\nNotice how much of the information this provides is also represented in the tibble output, very impressive!\n\n:::\n\n### Dealing with Missing Values at Read-in\n\nWhilst we cannot observe all missing values at this stage, examples that cause columns to be cast to unexpected data types are often spotted quickly.\n\nWe can easily correct this by adding the **na** paramter to the read_csv() function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specifying missing values as a vector to read_csv()\n\ntitanic_data <- read_csv(\"Data/titanic.csv\", \n                           na = c(\"*\", \".\", \"\", \"NULL\"))\n```\n:::\n\n\n\n\nThis is read as:\n\n> **Where there is the a full stop, asterisk, NULL (entirely empty) value or a blank space, class is it as a missing value.**\n\nWe can now see that the . and * in the age column have been replaced with NA's and the age column is now numeric.\n\nYou may see all sorts of missing values in practice, deriving from data entry:\n\n* negative numbers where it makes no sense\n* abnormally large values such as 999999\n\n>**There are many other useful arguments you can use when reading in data, check the help documentation for read_csv() for details.**\n\n\n## Readxl\n\nWe use readxl to read excel data into R, it supports both .xls and .xlsx formats.\n\nEven though it is installed alongside the tidyverse, it must be loaded separately.\n\nThe code for read in is very similar to the read_csv() example, just using the read_excel() function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load in readxl\n\nlibrary(readxl)\n```\n:::\n\n\n\n\nExcel workbooks are more complex than flat files as they are **workbooks**, featuring multiple sheets. \n\nWe can output their names using the excel_sheets() function, which will become important shortly.\n\n\n### Example \n\nLet's read in the police dataset.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Reading in excel data using the readxl package\n\npolice_data <- read_excel(\"Data/police_data.xlsx\")\n\nView(police_data)\n```\n:::\n\n\n\n\nWe see that this is the **first sheet** in our workbook which is just the \"Notes\". This is the default behaviour of read_excel() unless we specify otherwise.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Observe sheet names in police data\n\nexcel_sheets(\"Data/police_data.xlsx\")\n```\n:::\n\n\n\n\n\n### Exercise\n::: {.panel-tabset}\n\n### **Exercise**{-}\n\nUse an additional argument in \"read_excel()\" to read in the second sheet of the police dataset.\n\nYou will need to look at the help documentation for read_excel() to help you with this. \n\n\n### **Show Answer**{-}\n\nYou can use the name of the sheet or the number/index. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using the sheet parameter in 2 ways\n\npolice_data <- read_excel(\"Data/police_data.xlsx\",\n                          sheet = 2)\n\n# Alternatively\n\npolice_data <- read_excel(\"Data/police_data.xlsx\",\n                          sheet = \"Table P1\")\n\npolice_data\n```\n:::\n\n\n\n\nThis is better but still not ideal:\n\n* The top columns are mostly blank with no real significant data.\n\n    * We can get around this by specifying the **range** parameter in read_excel, to denote the range of cells to capture.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using the range parameter to avoid empty rows\n\n\npolice_data <- read_excel(\"Data/police_data.xlsx\",\n                          sheet = 2,\n                          range = \"A5:AA48\")\n\npolice_data\n```\n:::\n\n\n\n\n:::\n\n# Exporting the Data\n\nWhen you read a file into R, the data is loaded into memory. This means that any changes you make won't be reflected in the original file you loaded. \n\nIf you want to preserve the changes you make to the dataset you have to export the data object to its own file. \n\nWe have a family of functions for this, just like reading in, the **write_filetype()** functions.\n\n## Example\n\nAs an example, let's write out the police data which now has the correct sheet and range as a csv (flat) file instead.\n\nWe must supply two arguments to **write_csv()**:\n\n* dataset itself\n* file, which must be the filepath of **where to save your file**. \n\nThe path is constructed similarly as before\n\n>**\"../folder/my_file.csv\" as we must back out of the course_content folder first**\n\nIf you specify a folder that doesn't exist, the function will create it for you. In this case, let's create a separate folder called \"outputs\". \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exporting data using write_csv()\n\nwrite_csv(police_data, file = \"../outputs/police.csv\")\n```\n:::\n\n\n\n\nThis stores our police_data in the outputs folder under the name \"police.csv\". \n\n\n# Inspecting  the Data\n\nAfter importing our data, the first thing we may want to do is have a quick look at it:\n\n* We can check it looks similar to the source file.\n* We can check if there are the same number of rows and columns we expect.\n* We can check if the columns loaded in as the datatype we expect.\n* We can check if there are obvious missing values at the tail ends. \n\nWe can do these checks in a variety of ways, be that from base R, or in the tidyverse.\n\n## Inspecting Data Functions\n::: {.panel-tabset}\n\n### **Tail Ends**{-}\n\nWe can output the first or last 6 rows of the dataset by using the **head()** and **tail()** functions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Head of titanic\n\nhead(titanic_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tail of titanic\n\ntail(titanic_data)\n```\n:::\n\n\n\n\n### **Dimensions**{-}\n\nWe can output the number of rows and columns or each separately with the following functions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Number of rows in titanic\n\nnrow(titanic_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Number of columns in titanic\n\nncol(titanic_data)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Dimensions - Vector of nrow and ncol\n\ndim(titanic_data)\n```\n:::\n\n\n\n\n### **Column names**{-}\n\nWe can output the column names of a dataset as a vector using the **names()** function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Column names in titanic\n\nnames(titanic_data)\n```\n:::\n\n\n\n\n### **Glimpse (dplyr)**{-}\n\nUp to here, the functions prior were from base R, which the tibble deals with for us with its refined print method.\n\nThe tidyverse library has dplyr, a data manipulation package, that provides arguably the best inspection function, known as glimpse().\n\nThis refines the print even more, to just a snapshot of the content of the columns themselves. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Have a glimpse at titanic\n\nglimpse(titanic_data)\n```\n:::\n\n\n\n\nWe still retain much of the information from before:\n\n* The number of rows and columns\n* Column names\n* Column data types\n* The first 5-10 observations\n\nWe recommend using this function after each manipulation you make to the data, as a **sense check**.\n\n:::\n\n# Summary\n\nWell done for working your way through this solid introduction to the readr package in the tidyverse,\n\nBy no means are you expected to remember all the above, what is better is that you understand the problems you want to solve and can then use references or provided material to go about solving it.\n\nIn the next chapter we will look at data manipulation with the dplyr package from the tidyverse. \n",
    "supporting": [
      "CH3_import_export_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}